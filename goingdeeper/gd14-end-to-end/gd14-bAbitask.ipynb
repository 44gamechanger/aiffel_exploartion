{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "federal-cheat",
   "metadata": {},
   "source": [
    "# 14-6. 프로젝트: 한국어 QA 모델 만들기\n",
    "아래의 데이터셋은 bAbI 데이터셋을 저자가 한국어로 변환한 한국어 버전의 bAbI 데이터셋입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-republic",
   "metadata": {},
   "source": [
    "## [데이터셋 소개]\n",
    "데이터셋의 형태는 아래와 같이 영어 데이터셋과 동일합니다.\n",
    "\n",
    "```\n",
    "1 은경이는 복도로 가버렸습니다.\n",
    "2 필웅이는 화장실로 뛰어갔습니다.\n",
    "3 은경이는 어디야?     복도  1\n",
    "4 수종이는 화장실로 복귀했습니다.\n",
    "5 은경이는 침실로 갔습니다.\n",
    "6 필웅이는 어디야?     화장실 2\n",
    "7 은경이는 복도로 이동했습니다.\n",
    "8 경임이는 부엌으로 뛰어갔습니다.\n",
    "9 경임이는 어디야?     부엌  8\n",
    "10 경임이는 복도로 가버렸습니다.\n",
    "11 은경이는 정원으로 이동했습니다.\n",
    "12 경임이는 어디야?     복도  10\n",
    "13 경임이는 화장실로 복귀했습니다.\n",
    "14 경임이는 부엌으로 갔습니다.\n",
    "15 경임이는 어디야?     부엌  14\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-marshall",
   "metadata": {},
   "source": [
    "Step 1. 토크나이저 변경하기 (매우 중요!!!)\n",
    "영어권 언어는 띄어쓰기만해도 단어들이 잘 분리되지만, 한국어는 그렇지 않다고 앞에서 몇 차례 언급했었죠? 한국어 데이터를 사용하여 모델을 구현하는 것만큼 이번에는 형태소 분석기를 사용해서 단어 토큰화를 해보겠습니다.\n",
    "\n",
    "그런데 형태소 분석기를 사용할 때, 이런 상황에 봉착한다면 어떻게 해야할까요?\n",
    "```\n",
    "형태소 분석 입력 : '은경이는 사무실로 갔습니다.'\n",
    "형태소 분석 결과 : ['은', '경이', '는', '사무실', '로', '갔습니다', '.']\n",
    "```\n",
    "사실 위 문장에서 '은경이'는 사람 이름이므로 제대로 된 결과를 얻기 위해서는 '은', '경이'와 같이 글자가 분리되는 것이 아니라 '은경이' 또는 최소한 '은경'이라는 단어 토큰을 얻어야만 합니다.\n",
    "\n",
    "이런 경우에는 형태소 분석기에 사용자 사전을 추가해줄 수 있습니다.\n",
    "\n",
    "'은경이'는 하나의 단어이기 때문에 분리하지말라고 형태소 분석기에 알려주는 것이죠.\n",
    "\n",
    "사용자 사전을 추가하는 방법은 형태소 분석기마다 다소 다른데, 생각보다 복잡한 경우도 많습니다. 이번 실습에서는 Customized Konlpy라는 사용자 사전 추가가 매우 쉬운 패키지를 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-aurora",
   "metadata": {},
   "source": [
    "\n",
    "가령, 트위터라는 형태소 분석기를 사용한다고 하였을 때, '은경이'라는 단어를 사용자 사전에 추가하고 나서 문장을 형태소 분석하려면 어떻게 해야 할까요?\n",
    "\n",
    "```\n",
    "# 예시 코드\n",
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "resistant-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "plastic-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경에 맞게 경로 수정\n",
    "home_dir = os.getenv('HOME')+'/aiffel/babi_memory_net'\n",
    "\n",
    "# 환경에 맞게 경로 적절히 수정\n",
    "# DATA_DIR = home_dir + '/babi_memory_net'\n",
    "TRAIN_FILE = os.path.join(home_dir, \"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(home_dir, \"qa1_single-supporting-fact_test_kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "generous-terry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n",
      "2 은경이는 복도로 이동했습니다.\n",
      "3 필웅이는 어디야? \t화장실\t1\n",
      "4 수종이는 복도로 복귀했습니다.\n",
      "5 경임이는 정원으로 갔습니다.\n",
      "6 수종이는 어디야? \t복도\t4\n",
      "7 은경이는 사무실로 갔습니다.\n",
      "8 경임이는 화장실로 뛰어갔습니다.\n",
      "9 수종이는 어디야? \t복도\t4\n",
      "10 필웅이는 복도로 갔습니다.\n",
      "11 수종이는 사무실로 가버렸습니다.\n",
      "12 수종이는 어디야? \t사무실\t11\n",
      "13 은경이는 정원으로 복귀했습니다.\n",
      "14 은경이는 침실로 갔습니다.\n",
      "15 경임이는 어디야? \t화장실\t8\n",
      "1 경임이는 사무실로 가버렸습니다.\n",
      "2 경임이는 화장실로 이동했습니다.\n",
      "3 경임이는 어디야? \t화장실\t2\n",
      "4 필웅이는 침실로 이동했습니다.\n",
      "5 수종이는 복도로 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "colored-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "likely-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "atmospheric-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "theoretical-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 스토리 개수: 10000\n",
      "train 질문 개수: 10000\n",
      "train 답변 개수: 10000\n",
      "test 스토리 개수: 1000\n",
      "test 질문 개수: 1000\n",
      "test 답변 개수: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"train 스토리 개수:\", len(train_stories))\n",
    "print(\"train 질문 개수:\", len(train_questions))\n",
    "print(\"train 답변 개수:\", len(train_answers))\n",
    "print(\"test 스토리 개수:\", len(test_stories))\n",
    "print(\"test 질문 개수:\", len(test_questions))\n",
    "print(\"test 답변 개수:\", len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cultural-spanish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['수종이는 화장실로 뛰어갔습니다.',\n",
       " '경임이는 사무실로 갔습니다.',\n",
       " '은경이는 부엌으로 이동했습니다.',\n",
       " '경임이는 화장실로 갔습니다.',\n",
       " '수종이는 복도로 갔습니다.',\n",
       " '필웅이는 부엌으로 가버렸습니다.',\n",
       " '수종이는 부엌으로 이동했습니다.',\n",
       " '수종이는 화장실로 가버렸습니다.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "operating-transcription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['필웅이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '경임이는 어디야? ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dirty-sherman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화장실', '복도', '복도', '사무실', '화장실']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "declared-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시 코드\n",
    "from ckonlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('수종이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Noun')\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('필웅이', 'Noun')\n",
    "\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(sent):\n",
    "#     return [ x.strip() for x in re.sub(r\"\\s+|\\b\", '\\f', sent).split('\\f') if x.strip() ] # python 3.7의 경우 \n",
    "#     # return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()] # python 3.6의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "collaborative-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return twitter.morphs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "gorgeous-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "passing-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abroad-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'는': 1, '.': 2, '로': 3, '했습니다': 4, '으로': 5, '경임이': 6, '은경이': 7, '수종이': 8, '필웅이': 9, '이동': 10, '가버렸습니다': 11, '뛰어갔습니다': 12, '복귀': 13, '화장실': 14, '정원': 15, '복도': 16, '갔습니다': 17, '사무실': 18, '부엌': 19, '침실': 20, '어디': 21, '야': 22, '?': 23}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abroad-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ambient-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 70\n",
      "질문의 최대 길이 : 5\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "political-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "crazy-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "frank-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 70) (10000, 5) (10000, 24) (1000, 70) (1000, 5) (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "twenty-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "straight-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ordered-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : Tensor(\"input_1:0\", shape=(None, 70), dtype=float32)\n",
      "Question: Tensor(\"input_2:0\", shape=(None, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "toxic-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫 번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두 번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fatal-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "political-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m Tensor(\"sequential/Identity:0\", shape=(None, 70, 50), dtype=float32) \n",
      "\n",
      "Input encoded c Tensor(\"sequential_1/Identity:0\", shape=(None, 70, 5), dtype=float32) \n",
      "\n",
      "Question encoded Tensor(\"sequential_2/Identity:0\", shape=(None, 5, 50), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m, '\\n')\n",
    "print('Input encoded c', input_encoded_c, '\\n')\n",
    "print('Question encoded', question_encoded, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "animated-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape Tensor(\"activation/Identity:0\", shape=(None, 70, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "closing-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response shape Tensor(\"permute/Identity:0\", shape=(None, 5, 70), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "compact-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer shape Tensor(\"concatenate/Identity:0\", shape=(None, 5, 120), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "silver-knitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8873 - acc: 0.1654 - val_loss: 1.7957 - val_acc: 0.1490\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.7215 - acc: 0.2466 - val_loss: 1.5912 - val_acc: 0.3430\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5938 - acc: 0.3515 - val_loss: 1.5027 - val_acc: 0.3940\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4875 - acc: 0.4181 - val_loss: 1.4444 - val_acc: 0.4490\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4464 - acc: 0.4433 - val_loss: 1.4384 - val_acc: 0.4590\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4235 - acc: 0.4589 - val_loss: 1.4022 - val_acc: 0.4740\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3893 - acc: 0.4748 - val_loss: 1.3557 - val_acc: 0.5060\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3534 - acc: 0.4930 - val_loss: 1.3332 - val_acc: 0.5120\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3271 - acc: 0.4994 - val_loss: 1.2963 - val_acc: 0.5180\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2907 - acc: 0.5108 - val_loss: 1.2923 - val_acc: 0.5320\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2683 - acc: 0.5141 - val_loss: 1.2894 - val_acc: 0.4910\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2491 - acc: 0.5128 - val_loss: 1.2727 - val_acc: 0.5070\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2264 - acc: 0.5155 - val_loss: 1.2427 - val_acc: 0.5360\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2072 - acc: 0.5266 - val_loss: 1.2577 - val_acc: 0.5250\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1999 - acc: 0.5212 - val_loss: 1.2394 - val_acc: 0.5190\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1904 - acc: 0.5249 - val_loss: 1.2197 - val_acc: 0.5160\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1747 - acc: 0.5287 - val_loss: 1.2131 - val_acc: 0.5340\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1647 - acc: 0.5320 - val_loss: 1.2117 - val_acc: 0.5320\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1531 - acc: 0.5304 - val_loss: 1.2296 - val_acc: 0.5320\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1458 - acc: 0.5319 - val_loss: 1.2107 - val_acc: 0.5300\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1427 - acc: 0.5277 - val_loss: 1.2045 - val_acc: 0.5320\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1190 - acc: 0.5455 - val_loss: 1.2218 - val_acc: 0.5220\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1170 - acc: 0.5392 - val_loss: 1.2089 - val_acc: 0.5090\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1145 - acc: 0.5409 - val_loss: 1.2098 - val_acc: 0.5130\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1049 - acc: 0.5425 - val_loss: 1.2119 - val_acc: 0.5110\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0885 - acc: 0.5517 - val_loss: 1.2202 - val_acc: 0.5050\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0784 - acc: 0.5514 - val_loss: 1.2181 - val_acc: 0.5080\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0795 - acc: 0.5510 - val_loss: 1.2377 - val_acc: 0.5090\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0718 - acc: 0.5611 - val_loss: 1.2314 - val_acc: 0.5040\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0605 - acc: 0.5617 - val_loss: 1.2229 - val_acc: 0.4990\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0521 - acc: 0.5629 - val_loss: 1.2409 - val_acc: 0.4980\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0375 - acc: 0.5694 - val_loss: 1.2238 - val_acc: 0.5110\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0323 - acc: 0.5632 - val_loss: 1.2477 - val_acc: 0.5120\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0200 - acc: 0.5739 - val_loss: 1.2532 - val_acc: 0.5080\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0186 - acc: 0.5772 - val_loss: 1.2293 - val_acc: 0.5140\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0046 - acc: 0.5880 - val_loss: 1.2766 - val_acc: 0.5060\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9904 - acc: 0.5872 - val_loss: 1.2381 - val_acc: 0.5130\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9677 - acc: 0.6017 - val_loss: 1.1955 - val_acc: 0.5540\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8933 - acc: 0.6506 - val_loss: 1.0642 - val_acc: 0.6310\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7529 - acc: 0.7233 - val_loss: 0.8718 - val_acc: 0.6930\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6510 - acc: 0.7656 - val_loss: 0.7712 - val_acc: 0.7220\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5840 - acc: 0.7910 - val_loss: 0.7359 - val_acc: 0.7370\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5471 - acc: 0.8008 - val_loss: 0.7074 - val_acc: 0.7490\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4980 - acc: 0.8187 - val_loss: 0.6886 - val_acc: 0.7710\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4685 - acc: 0.8312 - val_loss: 0.5964 - val_acc: 0.7790\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4172 - acc: 0.8503 - val_loss: 0.5814 - val_acc: 0.7980\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3790 - acc: 0.8660 - val_loss: 0.5558 - val_acc: 0.8150\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3491 - acc: 0.8759 - val_loss: 0.4804 - val_acc: 0.8360\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3218 - acc: 0.8853 - val_loss: 0.4570 - val_acc: 0.8410\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3071 - acc: 0.8891 - val_loss: 0.4640 - val_acc: 0.8390\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2858 - acc: 0.8988 - val_loss: 0.4495 - val_acc: 0.8450\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2664 - acc: 0.9058 - val_loss: 0.4527 - val_acc: 0.8330\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2476 - acc: 0.9114 - val_loss: 0.4525 - val_acc: 0.8480\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2372 - acc: 0.9132 - val_loss: 0.4619 - val_acc: 0.8360\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2313 - acc: 0.9167 - val_loss: 0.4178 - val_acc: 0.8630\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2148 - acc: 0.9242 - val_loss: 0.4099 - val_acc: 0.8700\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2086 - acc: 0.9262 - val_loss: 0.4150 - val_acc: 0.8540\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1958 - acc: 0.9299 - val_loss: 0.3944 - val_acc: 0.8650\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1893 - acc: 0.9347 - val_loss: 0.3906 - val_acc: 0.8650\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1747 - acc: 0.9388 - val_loss: 0.4246 - val_acc: 0.8650\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1708 - acc: 0.9391 - val_loss: 0.4203 - val_acc: 0.8780\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1542 - acc: 0.9447 - val_loss: 0.3660 - val_acc: 0.8840\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1455 - acc: 0.9489 - val_loss: 0.3878 - val_acc: 0.8830\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1424 - acc: 0.9533 - val_loss: 0.3889 - val_acc: 0.8850\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1492 - acc: 0.9509 - val_loss: 0.3823 - val_acc: 0.8880\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1263 - acc: 0.9557 - val_loss: 0.3587 - val_acc: 0.8890\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1230 - acc: 0.9580 - val_loss: 0.4078 - val_acc: 0.8830\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1146 - acc: 0.9592 - val_loss: 0.3487 - val_acc: 0.8940\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1082 - acc: 0.9620 - val_loss: 0.4175 - val_acc: 0.8860\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1078 - acc: 0.9628 - val_loss: 0.3551 - val_acc: 0.9040\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0960 - acc: 0.9677 - val_loss: 0.3676 - val_acc: 0.8990\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0951 - acc: 0.9689 - val_loss: 0.3877 - val_acc: 0.8940\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0968 - acc: 0.9695 - val_loss: 0.3605 - val_acc: 0.8960\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0832 - acc: 0.9718 - val_loss: 0.3772 - val_acc: 0.9040\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0818 - acc: 0.9747 - val_loss: 0.3400 - val_acc: 0.9140\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0794 - acc: 0.9745 - val_loss: 0.3747 - val_acc: 0.9010\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0794 - acc: 0.9746 - val_loss: 0.3385 - val_acc: 0.9120\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0751 - acc: 0.9764 - val_loss: 0.3770 - val_acc: 0.9050\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0644 - acc: 0.9777 - val_loss: 0.3645 - val_acc: 0.9030\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0709 - acc: 0.9759 - val_loss: 0.3692 - val_acc: 0.9110\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0675 - acc: 0.9780 - val_loss: 0.3236 - val_acc: 0.9130\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0677 - acc: 0.9768 - val_loss: 0.3284 - val_acc: 0.9170\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0621 - acc: 0.9782 - val_loss: 0.3498 - val_acc: 0.9080\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0618 - acc: 0.9783 - val_loss: 0.3403 - val_acc: 0.9110\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0585 - acc: 0.9814 - val_loss: 0.3913 - val_acc: 0.9040\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0564 - acc: 0.9821 - val_loss: 0.3510 - val_acc: 0.9130\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0605 - acc: 0.9801 - val_loss: 0.3562 - val_acc: 0.9140\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0501 - acc: 0.9850 - val_loss: 0.3584 - val_acc: 0.9090\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0495 - acc: 0.9840 - val_loss: 0.3580 - val_acc: 0.9150\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0487 - acc: 0.9839 - val_loss: 0.3765 - val_acc: 0.9090\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0483 - acc: 0.9853 - val_loss: 0.3373 - val_acc: 0.9180\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0477 - acc: 0.9862 - val_loss: 0.3373 - val_acc: 0.9230\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0428 - acc: 0.9880 - val_loss: 0.3841 - val_acc: 0.9170\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0368 - acc: 0.9885 - val_loss: 0.3842 - val_acc: 0.9120\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0396 - acc: 0.9868 - val_loss: 0.3367 - val_acc: 0.9310\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0482 - acc: 0.9842 - val_loss: 0.3703 - val_acc: 0.9190\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0389 - acc: 0.9874 - val_loss: 0.3328 - val_acc: 0.9280\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0357 - acc: 0.9880 - val_loss: 0.3688 - val_acc: 0.9170\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0407 - acc: 0.9869 - val_loss: 0.3502 - val_acc: 0.9150\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0377 - acc: 0.9894 - val_loss: 0.3440 - val_acc: 0.9260\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0426 - acc: 0.9874 - val_loss: 0.3521 - val_acc: 0.9190\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0376 - acc: 0.9889 - val_loss: 0.3219 - val_acc: 0.9270\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0395 - acc: 0.9875 - val_loss: 0.3247 - val_acc: 0.9290\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0405 - acc: 0.9881 - val_loss: 0.3015 - val_acc: 0.9330\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.3321 - val_acc: 0.9330\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0451 - acc: 0.9866 - val_loss: 0.3324 - val_acc: 0.9300\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0403 - acc: 0.9890 - val_loss: 0.3667 - val_acc: 0.9260\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0330 - acc: 0.9901 - val_loss: 0.3175 - val_acc: 0.9360\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0344 - acc: 0.9900 - val_loss: 0.2881 - val_acc: 0.9330\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0349 - acc: 0.9889 - val_loss: 0.3004 - val_acc: 0.9350\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0315 - acc: 0.9909 - val_loss: 0.3270 - val_acc: 0.9300\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0324 - acc: 0.9903 - val_loss: 0.3410 - val_acc: 0.9300\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0285 - acc: 0.9915 - val_loss: 0.3363 - val_acc: 0.9270\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0358 - acc: 0.9886 - val_loss: 0.3284 - val_acc: 0.9320\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0401 - acc: 0.9891 - val_loss: 0.3079 - val_acc: 0.9390\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0344 - acc: 0.9907 - val_loss: 0.3783 - val_acc: 0.9230\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0325 - acc: 0.9891 - val_loss: 0.3912 - val_acc: 0.9220\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0289 - acc: 0.9914 - val_loss: 0.3618 - val_acc: 0.9350\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0291 - acc: 0.9915 - val_loss: 0.3573 - val_acc: 0.9320\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0236 - acc: 0.9934 - val_loss: 0.3823 - val_acc: 0.9320\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = os.getenv('HOME')+'/aiffel/babi_memory_net/model.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "regional-partition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3823 - acc: 0.9320\n",
      "\n",
      " 테스트 정확도: 0.9320\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "solved-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "written-spyware",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문                  |실제값    |예측값\n",
      "---------------------------------------\n",
      "은경이 는 어디 야 ?        : 복도       복도\n",
      "필웅이 는 어디 야 ?        : 화장실      화장실\n",
      "경임이 는 어디 야 ?        : 부엌       부엌\n",
      "경임이 는 어디 야 ?        : 복도       복도\n",
      "경임이 는 어디 야 ?        : 부엌       부엌\n",
      "경임이 는 어디 야 ?        : 복도       복도\n",
      "경임이 는 어디 야 ?        : 정원       정원\n",
      "수종이 는 어디 야 ?        : 복도       복도\n",
      "경임이 는 어디 야 ?        : 사무실      정원\n",
      "수종이 는 어디 야 ?        : 사무실      화장실\n",
      "필웅이 는 어디 야 ?        : 부엌       부엌\n",
      "필웅이 는 어디 야 ?        : 정원       정원\n",
      "수종이 는 어디 야 ?        : 사무실      사무실\n",
      "필웅이 는 어디 야 ?        : 침실       침실\n",
      "필웅이 는 어디 야 ?        : 침실       정원\n",
      "은경이 는 어디 야 ?        : 부엌       부엌\n",
      "은경이 는 어디 야 ?        : 정원       정원\n",
      "은경이 는 어디 야 ?        : 부엌       부엌\n",
      "수종이 는 어디 야 ?        : 사무실      사무실\n",
      "은경이 는 어디 야 ?        : 부엌       복도\n",
      "필웅이 는 어디 야 ?        : 복도       복도\n",
      "은경이 는 어디 야 ?        : 사무실      사무실\n",
      "은경이 는 어디 야 ?        : 사무실      사무실\n",
      "경임이 는 어디 야 ?        : 복도       복도\n",
      "수종이 는 어디 야 ?        : 침실       침실\n",
      "경임이 는 어디 야 ?        : 침실       침실\n",
      "필웅이 는 어디 야 ?        : 침실       침실\n",
      "수종이 는 어디 야 ?        : 부엌       부엌\n",
      "수종이 는 어디 야 ?        : 부엌       부엌\n",
      "수종이 는 어디 야 ?        : 부엌       화장실\n"
     ]
    }
   ],
   "source": [
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:20}|{:7}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:8} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-lesbian",
   "metadata": {},
   "source": [
    "## Step 2. 형태소 분석 후 불용어 처리하기\n",
    "형태소 분석기로 문자를 분석해보면 '는', '으로' 등 분석에 크게 도움이 되지 않을 것 같은 토큰들이 나올 거에요. 처음에는 이 토큰들도 그대로 사용해서 모델을 구현해보고, 두 번째 구현에서는 이 토큰들을 전처리 과정에서 불용어 처리하여 제외해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessible-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경에 맞게 경로 수정\n",
    "home_dir = os.getenv('HOME')+'/aiffel/babi_memory_net'\n",
    "\n",
    "# 환경에 맞게 경로 적절히 수정\n",
    "# DATA_DIR = home_dir + '/babi_memory_net'\n",
    "TRAIN_FILE = os.path.join(home_dir, \"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(home_dir, \"qa1_single-supporting-fact_test_kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "transsexual-vulnerability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n",
      "2 은경이는 복도로 이동했습니다.\n",
      "3 필웅이는 어디야? \t화장실\t1\n",
      "4 수종이는 복도로 복귀했습니다.\n",
      "5 경임이는 정원으로 갔습니다.\n",
      "6 수종이는 어디야? \t복도\t4\n",
      "7 은경이는 사무실로 갔습니다.\n",
      "8 경임이는 화장실로 뛰어갔습니다.\n",
      "9 수종이는 어디야? \t복도\t4\n",
      "10 필웅이는 복도로 갔습니다.\n",
      "11 수종이는 사무실로 가버렸습니다.\n",
      "12 수종이는 어디야? \t사무실\t11\n",
      "13 은경이는 정원으로 복귀했습니다.\n",
      "14 은경이는 침실로 갔습니다.\n",
      "15 경임이는 어디야? \t화장실\t8\n",
      "1 경임이는 사무실로 가버렸습니다.\n",
      "2 경임이는 화장실로 이동했습니다.\n",
      "3 경임이는 어디야? \t화장실\t2\n",
      "4 필웅이는 침실로 이동했습니다.\n",
      "5 수종이는 복도로 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reasonable-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dense-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "composed-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enclosed-algeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 스토리 개수: 10000\n",
      "train 질문 개수: 10000\n",
      "train 답변 개수: 10000\n",
      "test 스토리 개수: 1000\n",
      "test 질문 개수: 1000\n",
      "test 답변 개수: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"train 스토리 개수:\", len(train_stories))\n",
    "print(\"train 질문 개수:\", len(train_questions))\n",
    "print(\"train 답변 개수:\", len(train_answers))\n",
    "print(\"test 스토리 개수:\", len(test_stories))\n",
    "print(\"test 질문 개수:\", len(test_questions))\n",
    "print(\"test 답변 개수:\", len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "driving-lightning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['수종이는 화장실로 뛰어갔습니다.',\n",
       " '경임이는 사무실로 갔습니다.',\n",
       " '은경이는 부엌으로 이동했습니다.',\n",
       " '경임이는 화장실로 갔습니다.',\n",
       " '수종이는 복도로 갔습니다.',\n",
       " '필웅이는 부엌으로 가버렸습니다.',\n",
       " '수종이는 부엌으로 이동했습니다.',\n",
       " '수종이는 화장실로 가버렸습니다.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tribal-possibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['필웅이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '경임이는 어디야? ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "taken-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화장실', '복도', '복도', '사무실', '화장실']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "english-passenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시 코드\n",
    "from ckonlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('수종이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Noun')\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('필웅이', 'Noun')\n",
    "\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(sent):\n",
    "#     return [ x.strip() for x in re.sub(r\"\\s+|\\b\", '\\f', sent).split('\\f') if x.strip() ] # python 3.7의 경우 \n",
    "#     # return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()] # python 3.6의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "employed-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Postprocessor\n",
    "\n",
    "stopwords = {'는', '으로', '로', '야'}\n",
    "\n",
    "postprocessor = Postprocessor(\n",
    "    base_tagger = twitter,\n",
    "    stopwords = stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "center-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('은경이', 'Noun'), ('사무실', 'Noun'), ('갔습니다', 'Verb'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(postprocessor.pos('은경이는 사무실로 갔습니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "essential-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    sentence_post = []\n",
    "    sentence = postprocessor.pos(sent)\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        ko = sentence[i][0]\n",
    "        sentence_post.append(ko)\n",
    "    \n",
    "    \n",
    "    return sentence_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "boolean-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "oriental-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ongoing-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 1, '했습니다': 2, '경임이': 3, '은경이': 4, '수종이': 5, '필웅이': 6, '이동': 7, '가버렸습니다': 8, '뛰어갔습니다': 9, '복귀': 10, '화장실': 11, '정원': 12, '복도': 13, '갔습니다': 14, '사무실': 15, '부엌': 16, '침실': 17, '어디': 18, '?': 19}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "honest-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ranging-willow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 50\n",
      "질문의 최대 길이 : 3\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "agricultural-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "unavailable-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "respective-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50) (10000, 3) (10000, 20) (1000, 50) (1000, 3) (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "informational-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "proof-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "warming-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : Tensor(\"input_3:0\", shape=(None, 50), dtype=float32)\n",
      "Question: Tensor(\"input_4:0\", shape=(None, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "surprising-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫 번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두 번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "vocational-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "according-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m Tensor(\"sequential_3/Identity:0\", shape=(None, 50, 50), dtype=float32) \n",
      "\n",
      "Input encoded c Tensor(\"sequential_4/Identity:0\", shape=(None, 50, 3), dtype=float32) \n",
      "\n",
      "Question encoded Tensor(\"sequential_5/Identity:0\", shape=(None, 3, 50), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m, '\\n')\n",
    "print('Input encoded c', input_encoded_c, '\\n')\n",
    "print('Question encoded', question_encoded, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "minimal-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape Tensor(\"activation_2/Identity:0\", shape=(None, 50, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "latest-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response shape Tensor(\"permute_1/Identity:0\", shape=(None, 3, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "common-bunny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer shape Tensor(\"concatenate_1/Identity:0\", shape=(None, 3, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "secure-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8851 - acc: 0.1773 - val_loss: 1.8063 - val_acc: 0.1490\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.7874 - acc: 0.1902 - val_loss: 1.7157 - val_acc: 0.2700\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6793 - acc: 0.2795 - val_loss: 1.6555 - val_acc: 0.2580\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5800 - acc: 0.3677 - val_loss: 1.4912 - val_acc: 0.4260\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5113 - acc: 0.4020 - val_loss: 1.4887 - val_acc: 0.4150\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5005 - acc: 0.3993 - val_loss: 1.4602 - val_acc: 0.4280\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4598 - acc: 0.4332 - val_loss: 1.4249 - val_acc: 0.4490\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4108 - acc: 0.4424 - val_loss: 1.3534 - val_acc: 0.4750\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3811 - acc: 0.4565 - val_loss: 1.3567 - val_acc: 0.4400\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3665 - acc: 0.4634 - val_loss: 1.3213 - val_acc: 0.4920\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3532 - acc: 0.4700 - val_loss: 1.3259 - val_acc: 0.5050\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3434 - acc: 0.4802 - val_loss: 1.2987 - val_acc: 0.5100\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3222 - acc: 0.4907 - val_loss: 1.2881 - val_acc: 0.4960\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3067 - acc: 0.4993 - val_loss: 1.3117 - val_acc: 0.5200\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2980 - acc: 0.5035 - val_loss: 1.3452 - val_acc: 0.5000\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2835 - acc: 0.5046 - val_loss: 1.2932 - val_acc: 0.4790\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2732 - acc: 0.5112 - val_loss: 1.2602 - val_acc: 0.5180\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2706 - acc: 0.5081 - val_loss: 1.2547 - val_acc: 0.5170\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2554 - acc: 0.5126 - val_loss: 1.2723 - val_acc: 0.5230\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2552 - acc: 0.5111 - val_loss: 1.2474 - val_acc: 0.5190\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2442 - acc: 0.5173 - val_loss: 1.2749 - val_acc: 0.5230\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2318 - acc: 0.5226 - val_loss: 1.2624 - val_acc: 0.5260\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2309 - acc: 0.5179 - val_loss: 1.2554 - val_acc: 0.5230\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2213 - acc: 0.5239 - val_loss: 1.2325 - val_acc: 0.5200\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2039 - acc: 0.5372 - val_loss: 1.1986 - val_acc: 0.5490\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1684 - acc: 0.5554 - val_loss: 1.1418 - val_acc: 0.5730\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1093 - acc: 0.5839 - val_loss: 1.0337 - val_acc: 0.6110\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0121 - acc: 0.6403 - val_loss: 0.9035 - val_acc: 0.6780\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9095 - acc: 0.6779 - val_loss: 0.8064 - val_acc: 0.7200\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8291 - acc: 0.7033 - val_loss: 0.7614 - val_acc: 0.7420\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7812 - acc: 0.7236 - val_loss: 0.7117 - val_acc: 0.7610\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7348 - acc: 0.7420 - val_loss: 0.6682 - val_acc: 0.7670\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6749 - acc: 0.7542 - val_loss: 0.5792 - val_acc: 0.8000\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6252 - acc: 0.7773 - val_loss: 0.5353 - val_acc: 0.8110\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5725 - acc: 0.7941 - val_loss: 0.5550 - val_acc: 0.8010\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5374 - acc: 0.8084 - val_loss: 0.4511 - val_acc: 0.8420\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5096 - acc: 0.8111 - val_loss: 0.4646 - val_acc: 0.8300\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4886 - acc: 0.8211 - val_loss: 0.4295 - val_acc: 0.8520\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4766 - acc: 0.8244 - val_loss: 0.4855 - val_acc: 0.8180\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4587 - acc: 0.8288 - val_loss: 0.4091 - val_acc: 0.8550\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4440 - acc: 0.8366 - val_loss: 0.4401 - val_acc: 0.8330\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4333 - acc: 0.8397 - val_loss: 0.4337 - val_acc: 0.8290\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4214 - acc: 0.8432 - val_loss: 0.4114 - val_acc: 0.8400\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4127 - acc: 0.8495 - val_loss: 0.4027 - val_acc: 0.8480\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3991 - acc: 0.8508 - val_loss: 0.4168 - val_acc: 0.8370\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3911 - acc: 0.8557 - val_loss: 0.4185 - val_acc: 0.8290\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3879 - acc: 0.8557 - val_loss: 0.3812 - val_acc: 0.8570\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3762 - acc: 0.8580 - val_loss: 0.3781 - val_acc: 0.8590\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3580 - acc: 0.8655 - val_loss: 0.3415 - val_acc: 0.8810\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3503 - acc: 0.8719 - val_loss: 0.3503 - val_acc: 0.8690\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3467 - acc: 0.8734 - val_loss: 0.3366 - val_acc: 0.8830\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3395 - acc: 0.8760 - val_loss: 0.3713 - val_acc: 0.8540\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3301 - acc: 0.8788 - val_loss: 0.3678 - val_acc: 0.8640\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3167 - acc: 0.8867 - val_loss: 0.3330 - val_acc: 0.8810\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3095 - acc: 0.8906 - val_loss: 0.3130 - val_acc: 0.8840\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2992 - acc: 0.8905 - val_loss: 0.3082 - val_acc: 0.8930\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2958 - acc: 0.8925 - val_loss: 0.3171 - val_acc: 0.8930\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2771 - acc: 0.8981 - val_loss: 0.2722 - val_acc: 0.9060\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2715 - acc: 0.9048 - val_loss: 0.2778 - val_acc: 0.9010\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2624 - acc: 0.9089 - val_loss: 0.2704 - val_acc: 0.8970\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2586 - acc: 0.9061 - val_loss: 0.2638 - val_acc: 0.9100\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2528 - acc: 0.9066 - val_loss: 0.2528 - val_acc: 0.9130\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2447 - acc: 0.9140 - val_loss: 0.2571 - val_acc: 0.9080\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2366 - acc: 0.9139 - val_loss: 0.2507 - val_acc: 0.9160\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2260 - acc: 0.9200 - val_loss: 0.2207 - val_acc: 0.9210\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2225 - acc: 0.9228 - val_loss: 0.2555 - val_acc: 0.9080\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2083 - acc: 0.9280 - val_loss: 0.2251 - val_acc: 0.9250\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2113 - acc: 0.9256 - val_loss: 0.2090 - val_acc: 0.9330\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2014 - acc: 0.9280 - val_loss: 0.2710 - val_acc: 0.9000\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1948 - acc: 0.9320 - val_loss: 0.1932 - val_acc: 0.9400\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1925 - acc: 0.9344 - val_loss: 0.2171 - val_acc: 0.9250\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1888 - acc: 0.9316 - val_loss: 0.1901 - val_acc: 0.9360\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1806 - acc: 0.9375 - val_loss: 0.2368 - val_acc: 0.9190\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1756 - acc: 0.9353 - val_loss: 0.1932 - val_acc: 0.9340\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1762 - acc: 0.9360 - val_loss: 0.1983 - val_acc: 0.9340\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1779 - acc: 0.9376 - val_loss: 0.1906 - val_acc: 0.9420\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1662 - acc: 0.9430 - val_loss: 0.1780 - val_acc: 0.9350\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1644 - acc: 0.9427 - val_loss: 0.1899 - val_acc: 0.9290\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1605 - acc: 0.9454 - val_loss: 0.1904 - val_acc: 0.9390\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1597 - acc: 0.9418 - val_loss: 0.1528 - val_acc: 0.9520\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1517 - acc: 0.9465 - val_loss: 0.1691 - val_acc: 0.9420\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1453 - acc: 0.9479 - val_loss: 0.1685 - val_acc: 0.9460\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1380 - acc: 0.9533 - val_loss: 0.1423 - val_acc: 0.9570\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1372 - acc: 0.9529 - val_loss: 0.1609 - val_acc: 0.9440\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1378 - acc: 0.9502 - val_loss: 0.1341 - val_acc: 0.9550\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1367 - acc: 0.9498 - val_loss: 0.1531 - val_acc: 0.9490\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1322 - acc: 0.9515 - val_loss: 0.1298 - val_acc: 0.9550\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1311 - acc: 0.9544 - val_loss: 0.1473 - val_acc: 0.9510\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1279 - acc: 0.9529 - val_loss: 0.1714 - val_acc: 0.9470\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1227 - acc: 0.9586 - val_loss: 0.1401 - val_acc: 0.9550\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1161 - acc: 0.9626 - val_loss: 0.1555 - val_acc: 0.9420\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1087 - acc: 0.9607 - val_loss: 0.1245 - val_acc: 0.9580\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1133 - acc: 0.9602 - val_loss: 0.1279 - val_acc: 0.9640\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1099 - acc: 0.9588 - val_loss: 0.1167 - val_acc: 0.9630\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1142 - acc: 0.9605 - val_loss: 0.1205 - val_acc: 0.9660\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1149 - acc: 0.9624 - val_loss: 0.1168 - val_acc: 0.9650\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1115 - acc: 0.9634 - val_loss: 0.1357 - val_acc: 0.9540\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1016 - acc: 0.9658 - val_loss: 0.1076 - val_acc: 0.9660\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1041 - acc: 0.9646 - val_loss: 0.1080 - val_acc: 0.9640\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0936 - acc: 0.9686 - val_loss: 0.1230 - val_acc: 0.9580\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1062 - acc: 0.9659 - val_loss: 0.1102 - val_acc: 0.9620\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0999 - acc: 0.9674 - val_loss: 0.1246 - val_acc: 0.9650\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0988 - acc: 0.9678 - val_loss: 0.1325 - val_acc: 0.9600\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0942 - acc: 0.9687 - val_loss: 0.1106 - val_acc: 0.9670\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0884 - acc: 0.9710 - val_loss: 0.1091 - val_acc: 0.9660\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0948 - acc: 0.9695 - val_loss: 0.1141 - val_acc: 0.9710\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0895 - acc: 0.9704 - val_loss: 0.1194 - val_acc: 0.9610\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0844 - acc: 0.9729 - val_loss: 0.1025 - val_acc: 0.9760\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0961 - acc: 0.9715 - val_loss: 0.1163 - val_acc: 0.9700\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9713 - val_loss: 0.1018 - val_acc: 0.9670\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9719 - val_loss: 0.1470 - val_acc: 0.9590\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0854 - acc: 0.9706 - val_loss: 0.1020 - val_acc: 0.9740\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0869 - acc: 0.9722 - val_loss: 0.0961 - val_acc: 0.9690\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0862 - acc: 0.9744 - val_loss: 0.1067 - val_acc: 0.9710\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0734 - acc: 0.9754 - val_loss: 0.1191 - val_acc: 0.9650\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0778 - acc: 0.9759 - val_loss: 0.1083 - val_acc: 0.9630\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0869 - acc: 0.9720 - val_loss: 0.1081 - val_acc: 0.9670\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0781 - acc: 0.9748 - val_loss: 0.1000 - val_acc: 0.9660\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0678 - acc: 0.9790 - val_loss: 0.0876 - val_acc: 0.9760\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0782 - acc: 0.9752 - val_loss: 0.1059 - val_acc: 0.9650\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = os.getenv('HOME')+'/aiffel/babi_memory_net/model.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "deadly-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1059 - acc: 0.9650\n",
      "\n",
      " 테스트 정확도: 0.9650\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "collectible-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "earlier-professional",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문                  |실제값    |예측값\n",
      "---------------------------------------\n",
      "은경이 어디 ?            : 복도       복도\n",
      "필웅이 어디 ?            : 화장실      화장실\n",
      "경임이 어디 ?            : 부엌       부엌\n",
      "경임이 어디 ?            : 복도       복도\n",
      "경임이 어디 ?            : 부엌       부엌\n",
      "경임이 어디 ?            : 복도       복도\n",
      "경임이 어디 ?            : 정원       정원\n",
      "수종이 어디 ?            : 복도       복도\n",
      "경임이 어디 ?            : 사무실      사무실\n",
      "수종이 어디 ?            : 사무실      사무실\n",
      "필웅이 어디 ?            : 부엌       부엌\n",
      "필웅이 어디 ?            : 정원       정원\n",
      "수종이 어디 ?            : 사무실      사무실\n",
      "필웅이 어디 ?            : 침실       침실\n",
      "필웅이 어디 ?            : 침실       침실\n",
      "은경이 어디 ?            : 부엌       부엌\n",
      "은경이 어디 ?            : 정원       정원\n",
      "은경이 어디 ?            : 부엌       부엌\n",
      "수종이 어디 ?            : 사무실      사무실\n",
      "은경이 어디 ?            : 부엌       부엌\n",
      "필웅이 어디 ?            : 복도       복도\n",
      "은경이 어디 ?            : 사무실      사무실\n",
      "은경이 어디 ?            : 사무실      사무실\n",
      "경임이 어디 ?            : 복도       복도\n",
      "수종이 어디 ?            : 침실       침실\n",
      "경임이 어디 ?            : 침실       침실\n",
      "필웅이 어디 ?            : 침실       침실\n",
      "수종이 어디 ?            : 부엌       부엌\n",
      "수종이 어디 ?            : 부엌       부엌\n",
      "수종이 어디 ?            : 부엌       부엌\n"
     ]
    }
   ],
   "source": [
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:20}|{:7}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:8} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-christopher",
   "metadata": {},
   "source": [
    "## Step 3. 한국어에서의 모델 정확도 확인해보기\n",
    "앞서 만든 메모리 네트워크는 영어권 데이터에서는 보편적으로 약 96% 이상의 높은 성능을 보입니다. 하이퍼파라미터를 잘 조정하면 이보다 더 높은 정확도가 나오기도 합니다. 그렇다면 메모리 네트워크가 한국어에서도 영어만큼 잘 동작할까요? 직접 확인해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-apple",
   "metadata": {},
   "source": [
    "# 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-wealth",
   "metadata": {},
   "source": [
    "## 루브릭 \n",
    "\n",
    "1. 한국어의 특성에 알맞게 전처리가 진행되었다.\n",
    "- 한국어 특성에 따른 토큰화, 임베딩을 거쳐 데이터셋이 적절히 구성되었다.\n",
    "    - 결과: 노드를 따라 해보니 할 수 있었다.\n",
    "    \n",
    "2. 메모리 네트워크가 정상적으로 구현되어 학습이 안정적으로 진행되었다.\n",
    "- validation loss가 안정적으로 수렴하는 것을 확인하고 이를 시각화하였다.\n",
    "    - 결과: 불용어 제거 전 모델과, 제거 후 모델 모두 안정적으로 그래프가 나타났다.\n",
    "\n",
    "3. 메모리 네트워크를 통해 한국어 bAbI 태스크의 높은 정확도를 달성하였다.\n",
    "- 추론 태스크의 테스트 정확도가 90% 이상 달성하였다.\n",
    "    - 결과: 불용어 제거 전에는 93.2%였지만 불용어 제거 후 96.5%를 얻을 수 있었다.\n",
    "    \n",
    "## 느낀점\n",
    "\n",
    "이번 노드는 나도 충분히 해낼 수 있는 노드였다. 이렇게 해결하는 것이 맞는지 모르겠지만 불용어 제거 하는 것을 어떻게 하는지 몰라 난감했다. 그러다 postproceccer.pos(sent)를 찍어보니 단어와 그 단어의 품사가 같이 나오는 것을 알았고 리스트에 단어만 받는 것으로 바꿔보니 해결이 되었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-struggle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-franklin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-stability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-official",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-group",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-farmer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-spectacular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-generic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-facial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-fraction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-alpha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-junior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-karaoke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-perry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-glenn",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-causing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-thousand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-biography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-radar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-stomach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-being",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-extraction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-console",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-former",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-wells",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-eleven",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-penguin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-harvard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-rough",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-immigration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-guide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-origin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-toyota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-floating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-shield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-journal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-storm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-consumer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-utilization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-screen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-finding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-christopher",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
