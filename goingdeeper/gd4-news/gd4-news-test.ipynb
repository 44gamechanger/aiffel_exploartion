{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divine-martin",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-margin",
   "metadata": {},
   "source": [
    "# 4-9. 프로젝트: Vocabulary Size를 변경해서 시도해보기\n",
    "지금까지는 모델을 변경하고, 모델을 조합해서 성능을 올리는 일에 힘썼습니다. 그런데 어쩌면 성능을 높이는 방법은 단순히 모델을 조정하는 일이 한정되지 않을 수 있습니다. 데이터의 전처리는 모델의 성능에 영향을 직접적으로 줍니다. 특히나 Bag of Words를 기반으로 하는 DTM이나 TF-IDF의 경우, 사용하는 단어의 수를 어떻게 결정하느냐에 따라서 성능에 영향을 줄 수 있겠죠.\n",
    "\n",
    "중요도가 낮은 단어들까지 포함해서 너무 많은 단어를 사용하는 경우에도 성능이 저하될 수 있고, 반대로 너무 적은 단어들을 사용해도 성능이 저하될 수 있습니다. 그리고 이렇게 변화된 단어의 수는 또 어떤 모델을 사용하느냐에 따라 유리할 수도, 불리할 수도 있습니다.\n",
    "\n",
    "단어의 수에 따라서 모델의 성능이 어떻게 변하는지 테스트해 봅시다.\n",
    "\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "```\n",
    "\n",
    "앞서 num_words로 사용할 단어의 수를 조정할 수 있다는 것을 배웠습니다. 빈도수가 많은 순서대로 나열했을 때, num_words의 인자로 준 정숫값만큼의 단어를 사용하고 나머지 단어는 전부 <unk>로 처리하는 원리였었죠.\n",
    "\n",
    "아래의 두 가지 경우에 대해서 지금까지 사용했던 모델들의 정확도를 직접 확인해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-performer",
   "metadata": {},
   "source": [
    "## 1. 모든 단어 사용\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-prediction",
   "metadata": {},
   "source": [
    "## 2. 빈도수 상위 5,000개의 단어만 사용\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-information",
   "metadata": {},
   "source": [
    "## 3. 직접 단어 갯수를 설정해서 사용\n",
    "위 단계에서 5000으로 제시된 num_words를 다양하게 바꾸어 가며 성능을 확인해보세요. 변화된 단어 수에 따른 모델의 성능을 연구해 보세요. 최소 3가지 경우 이상을 실험해 보기를 권합니다.\n",
    "\n",
    "사용할 모델\n",
    "\n",
    "나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-shirt",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 모델과 비교해 보기\n",
    "위 과정을 통해 나온 최적의 모델과 단어 수 조건에서, 본인이 선택한 다른 모델을 적용한 결과와 비교해 봅시다. 감정분석 등에 사용했던 RNN이나 1-D CNN 등의 딥러닝 모델 중 하나를 선택해서 오늘 사용했던 데이터셋을 학습해 보고 나오는 결과를 비교해 봅시다. 단, 공정한 비교를 위해 이때 Word2Vec 등의 pretrained model은 사용하지 않도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-bullet",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-bloom",
   "metadata": {},
   "source": [
    "# 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranging-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-prototype",
   "metadata": {},
   "source": [
    "## 1. 모든 단어 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-exclusion",
   "metadata": {},
   "source": [
    "### -1. train, test 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unavailable-monaco",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conditional-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 수 : 8982\n",
      "테스트 샘플 수 : 2246\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성 확인\n",
    "print('훈련 샘플 수 : {}'.format(len(x_train)))\n",
    "print('테스트 샘플 수 : {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-insulation",
   "metadata": {},
   "source": [
    "### -2. 원본 뉴스 데이터로 복원(정수 데이터 -> 텍스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chubby-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래와 같이 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 딕셔너리를 제공함. 이를 word_index에 저장하겠음\n",
    "\n",
    "word_index = reuters.get_word_index(path='reuters_word_index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "modified-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +3 해주기\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "phantom-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터의 0, 1, 2 번은 <pad>, <sos>, <unk>라는 자연어 처리를 위한 특별한 토큰들을 위해 맵핑되어진 번호.  \n",
    "# 그래서 만들어진 index_to_word에 추가적으로 이 작업을 해주어야 진짜 index_to_word가 완성됨\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣어 줌\n",
    "\n",
    "for index, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "monthly-investor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word로 첫번째 훈련용 뉴스 기사를 원래 텍스트로 복원\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-chaos",
   "metadata": {},
   "source": [
    "### -3. 전체 훈련용 뉴스 데이터와 테스트 데이터를 텍스트 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "established-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comprehensive-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-casino",
   "metadata": {},
   "source": [
    "### -4. 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "respective-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "# DTM은 사이킷런의 CountVectorizer()을 통해서 생성할 수 있음\n",
    "# DTM을 생성하고, DTM의 크기를 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-packing",
   "metadata": {},
   "source": [
    "### -5. DTM을 사용해 TF-IDF로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "protected-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF는 사이킷런의 TfidfTrnsformer()을 통해서 생성 가능  \n",
    "# TF-IDF는 추가적인 전처리를 하지 않는 이상 DTM과 동일한 크기를 가짐\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-tradition",
   "metadata": {},
   "source": [
    "### -6. 사이킷런에서 제공하는 머신러닝 모델은 공통적으로 fit()함수를 통해 학습 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-savage",
   "metadata": {},
   "source": [
    "#### -6.1 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "successful-savannah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나이브 베이즈 분류기는 사이킷런의 MultinomialNB()를 통해 사용 가능\n",
    "\n",
    "# 사이킷런이 제공하는 머신러닝 모델들은 공통적으로 fit()이라는 함수를 제공하고 있는데\n",
    "# 훈련데이터와 해당 훈련 데이터에 대한 레이블을 인자로 사용하면 모델이 이를 학습함\n",
    "\n",
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "historic-operator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.5997328584149599\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 함.  \n",
    "# 다시말해 테스트 데이터도 TF-IDF행렬로 변환해주어야 함. 해당 행렬과 predict() 함수를 통해 에측값을 얻어 정확도를 측정함.\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) # 테스트 데이터를 dtm으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) # dtm을 tf-idf로 변환\n",
    "\n",
    "predicted1 = mod.predict(tfidfv_test) # 테스트 데이터에 대한 예측\n",
    "print('정확도: ', accuracy_score(y_test, predicted1)) # 예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-bracket",
   "metadata": {},
   "source": [
    "#### -6.2 CNB(Complement Naive Bayes Classifier)\n",
    "#### 나이브 베이즈 분류기를 보완한 것. 데이터의 불균형을 고려하여 가중치를 부여하는 특징이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unable-village",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "insured-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7649154051647373\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted2)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-alfred",
   "metadata": {},
   "source": [
    "#### -6.3 로지스틱 회귀(Logistic Regression)(이름은 회귀지만 분류를 수행)\n",
    "#### 소프트맥스 함수를 사용한 다중 클래스 분류 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sensitive-causing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "small-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.813446126447017\n"
     ]
    }
   ],
   "source": [
    "predicted3 = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted3)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-beast",
   "metadata": {},
   "source": [
    "#### -6.4 SVM\n",
    "#### 서포트 벡터(디시전 바운더리에서 가장 가까운 데이터?)만 사용해서 계산랸이 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "proud-veteran",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "proved-programming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7773820124666073\n"
     ]
    }
   ],
   "source": [
    "predicted4 = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted4)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-preparation",
   "metadata": {},
   "source": [
    "#### -6.5 결정 트리(decision tree)\n",
    "#### 스무고개 처럼 예/아니오 질문을 통해 학습, 트리계열의 모델들은  고차원이고 희소한 데이터에 대해서는 성능이 별로 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "prescription-insulin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "finite-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6211041852181657\n"
     ]
    }
   ],
   "source": [
    "predicted5 = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted5)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-venue",
   "metadata": {},
   "source": [
    "#### -6.6 랜덤 포레스트(Random Forest)\n",
    "#### 결정 트리는 과적합 될 수 있으나 랜덤포레스트는 결정트리보다 오버피팅 가능성이 적음\n",
    "#### 여러개의 나무들이 오렌지인지 사과인지 예측하여 각자의 결과를 투표로 모아서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "external-deficit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 포레스트 훈련\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surrounded-syntax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6544968833481746\n"
     ]
    }
   ],
   "source": [
    "predicted6 = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted6)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-height",
   "metadata": {},
   "source": [
    "#### -6.7 그래디언트 부스팅 트리\n",
    "#### 여러개의 결정 트리를 묶어 만드는 앙상블 모델. 랜덤 포레스트와 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦\n",
    "#### 일반적으로 1-5정도의 깊지 않은 트리만 사용하기 때문에 메모리도 적게 사용하고 예측도 빠름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "devoted-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12845.1851           13.60m\n",
      "         2   689466281.7264           13.37m\n",
      "         3 6884613407215.1387           13.39m\n",
      "         4 5935818824582923550720.0000           13.16m\n",
      "         5 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           12.88m\n",
      "         6 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           12.56m\n",
      "         7 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           12.42m\n",
      "         8 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           12.29m\n",
      "         9 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           12.16m\n",
      "        10 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           12.03m\n",
      "        11 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           11.84m\n",
      "        12 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           11.58m\n",
      "        13 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           11.46m\n",
      "        14 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           11.34m\n",
      "        15 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           11.22m\n",
      "        16 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           11.10m\n",
      "        17 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           10.97m\n",
      "        18 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           10.85m\n",
      "        19 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           10.72m\n",
      "        20 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           10.59m\n",
      "        21 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           10.46m\n",
      "        22 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           10.33m\n",
      "        23 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000           10.14m\n",
      "        24 9040644020576697454476775298309462042959687372080133879675061827235923374847613060426279764553817024942513812241979907601155443654656.0000            9.99m\n",
      "        25 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            9.84m\n",
      "        26 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            9.66m\n",
      "        27 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            9.48m\n",
      "        28 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            9.32m\n",
      "        29 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            9.19m\n",
      "        30 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            9.07m\n",
      "        31 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.95m\n",
      "        32 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.83m\n",
      "        33 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.70m\n",
      "        34 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.55m\n",
      "        35 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.39m\n",
      "        36 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.26m\n",
      "        37 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.14m\n",
      "        38 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            8.00m\n",
      "        39 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.87m\n",
      "        40 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.73m\n",
      "        41 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.59m\n",
      "        42 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.47m\n",
      "        43 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.33m\n",
      "        44 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.18m\n",
      "        45 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.04m\n",
      "        46 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            6.92m\n",
      "        47 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            6.78m\n",
      "        48 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            6.65m\n",
      "        49 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            6.53m\n",
      "        50 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            6.41m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        51 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            6.27m\n",
      "        52 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            6.13m\n",
      "        53 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.99m\n",
      "        54 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.87m\n",
      "        55 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.74m\n",
      "        56 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.62m\n",
      "        57 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.50m\n",
      "        58 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.37m\n",
      "        59 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.25m\n",
      "        60 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.12m\n",
      "        61 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            5.00m\n",
      "        62 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            4.87m\n",
      "        63 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            4.75m\n",
      "        64 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            4.62m\n",
      "        65 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            4.49m\n",
      "        66 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            4.35m\n",
      "        67 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            4.22m\n",
      "        68 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            4.08m\n",
      "        69 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.95m\n",
      "        70 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.83m\n",
      "        71 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.70m\n",
      "        72 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.58m\n",
      "        73 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.45m\n",
      "        74 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.32m\n",
      "        75 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.20m\n",
      "        76 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            3.07m\n",
      "        77 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.94m\n",
      "        78 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.82m\n",
      "        79 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.69m\n",
      "        80 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.56m\n",
      "        81 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.44m\n",
      "        82 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.30m\n",
      "        83 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.17m\n",
      "        84 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            2.04m\n",
      "        85 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.92m\n",
      "        86 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.79m\n",
      "        87 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.66m\n",
      "        88 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.54m\n",
      "        89 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.41m\n",
      "        90 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.28m\n",
      "        91 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.15m\n",
      "        92 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            1.02m\n",
      "        93 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000           53.53s\n",
      "        94 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000           45.85s\n",
      "        95 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000           38.21s\n",
      "        96 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000           30.59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        97 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000           22.95s\n",
      "        98 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000           15.31s\n",
      "        99 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            7.65s\n",
      "       100 71276538223797627407516241100862978529530963044983872457904873785026599868454939389911852427245548475410496325767775571272401790294044479567429632.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0, verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 약 12분 정도 소요 됨\n",
    "grbt = GradientBoostingClassifier(random_state=0, verbose=3) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "complex-recording",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7702582368655387\n"
     ]
    }
   ],
   "source": [
    "predicted7 = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted7)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "determined-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### -6.8 보팅\n",
    "#### 하드보팅 : 투표용지를 하나씩 주는 것  \n",
    "#### 소프트보팅 : 0부터 9중에서 0을 찾는 것이면 0~9 각 레이블마다 예측한 값을 기록하여 그 값을 평균내서 사용하는 것?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "private-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 로지스틱 회귀, CNB, 그래디언트 부스팅 트리 세가지 사용하여 소프트 보팅으로 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "optional-lewis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0,\n",
       "                                                         verbose=3))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0, verbose=3))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "theoretical-geology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8187889581478184\n"
     ]
    }
   ],
   "source": [
    "predicted8 = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted8)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "outstanding-power",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.5997328584149599\n",
      "CNB 정확도: 0.7649154051647373\n",
      "로지스틱 회귀 정확도: 0.813446126447017\n",
      "SVM 정확도: 0.7773820124666073\n",
      "결정 트리 정확도: 0.6211041852181657\n",
      "랜덤 포레스트 정확도: 0.6544968833481746\n",
      "그래디언트 부스팅 트리 정확도: 0.7702582368655387\n",
      "보팅 정확도: 0.8187889581478184\n"
     ]
    }
   ],
   "source": [
    "print(\"나이브 베이즈 정확도:\", accuracy_score(y_test, predicted1))\n",
    "print(\"CNB 정확도:\", accuracy_score(y_test, predicted2))\n",
    "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted3))\n",
    "print(\"SVM 정확도:\", accuracy_score(y_test, predicted4))\n",
    "print(\"결정 트리 정확도:\", accuracy_score(y_test, predicted5))\n",
    "print(\"랜덤 포레스트 정확도:\", accuracy_score(y_test, predicted6))\n",
    "print(\"그래디언트 부스팅 트리 정확도:\", accuracy_score(y_test, predicted7))\n",
    "print(\"보팅 정확도:\", accuracy_score(y_test, predicted8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-foster",
   "metadata": {},
   "source": [
    "## 1. 빈도수 상위 5000 단어 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-skill",
   "metadata": {},
   "source": [
    "### -1. train, test 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pregnant-africa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "premium-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 수 : 8982\n",
      "테스트 샘플 수 : 2246\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성 확인\n",
    "print('훈련 샘플 수 : {}'.format(len(x_train)))\n",
    "print('테스트 샘플 수 : {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-playback",
   "metadata": {},
   "source": [
    "### -2. 원본 뉴스 데이터로 복원(정수 데이터 -> 텍스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dated-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래와 같이 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 딕셔너리를 제공함. 이를 word_index에 저장하겠음\n",
    "\n",
    "word_index = reuters.get_word_index(path='reuters_word_index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "imported-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +3 해주기\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "vital-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터의 0, 1, 2 번은 <pad>, <sos>, <unk>라는 자연어 처리를 위한 특별한 토큰들을 위해 맵핑되어진 번호.  \n",
    "# 그래서 만들어진 index_to_word에 추가적으로 이 작업을 해주어야 진짜 index_to_word가 완성됨\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣어 줌\n",
    "\n",
    "for index, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "unique-bread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word로 첫번째 훈련용 뉴스 기사를 원래 텍스트로 복원\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-inspector",
   "metadata": {},
   "source": [
    "### -3. 전체 훈련용 뉴스 데이터와 테스트 데이터를 텍스트 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "chronic-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "nutritional-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-guinea",
   "metadata": {},
   "source": [
    "### -4. 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "worth-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "# DTM은 사이킷런의 CountVectorizer()을 통해서 생성할 수 있음\n",
    "# DTM을 생성하고, DTM의 크기를 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-trauma",
   "metadata": {},
   "source": [
    "### -5. DTM을 사용해 TF-IDF로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "pointed-restaurant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF는 사이킷런의 TfidfTrnsformer()을 통해서 생성 가능  \n",
    "# TF-IDF는 추가적인 전처리를 하지 않는 이상 DTM과 동일한 크기를 가짐\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-tribune",
   "metadata": {},
   "source": [
    "### -6. 사이킷런에서 제공하는 머신러닝 모델은 공통적으로 fit()함수를 통해 학습 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-roller",
   "metadata": {},
   "source": [
    "#### -6.1 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "static-booth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나이브 베이즈 분류기는 사이킷런의 MultinomialNB()를 통해 사용 가능\n",
    "\n",
    "# 사이킷런이 제공하는 머신러닝 모델들은 공통적으로 fit()이라는 함수를 제공하고 있는데\n",
    "# 훈련데이터와 해당 훈련 데이터에 대한 레이블을 인자로 사용하면 모델이 이를 학습함\n",
    "\n",
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "functioning-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.6731967943009796\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 함.  \n",
    "# 다시말해 테스트 데이터도 TF-IDF행렬로 변환해주어야 함. 해당 행렬과 predict() 함수를 통해 에측값을 얻어 정확도를 측정함.\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) # 테스트 데이터를 dtm으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) # dtm을 tf-idf로 변환\n",
    "\n",
    "predicted1 = mod.predict(tfidfv_test) # 테스트 데이터에 대한 예측\n",
    "print('정확도: ', accuracy_score(y_test, predicted1)) # 예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-fundamentals",
   "metadata": {},
   "source": [
    "#### -6.2 CNB(Complement Naive Bayes Classifier)\n",
    "#### 나이브 베이즈 분류기를 보완한 것. 데이터의 불균형을 고려하여 가중치를 부여하는 특징이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "reduced-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "duplicate-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted2)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-american",
   "metadata": {},
   "source": [
    "#### -6.3 로지스틱 회귀(Logistic Regression)(이름은 회귀지만 분류를 수행)\n",
    "#### 소프트맥스 함수를 사용한 다중 클래스 분류 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "spatial-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "graphic-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8058771148708815\n"
     ]
    }
   ],
   "source": [
    "predicted3 = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted3)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-tooth",
   "metadata": {},
   "source": [
    "#### -6.4 SVM\n",
    "#### 서포트 벡터(디시전 바운더리에서 가장 가까운 데이터?)만 사용해서 계산랸이 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "transsexual-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "intense-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7666963490650045\n"
     ]
    }
   ],
   "source": [
    "predicted4 = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted4)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-minneapolis",
   "metadata": {},
   "source": [
    "#### -6.5 결정 트리(decision tree)\n",
    "#### 스무고개 처럼 예/아니오 질문을 통해 학습, 트리계열의 모델들은  고차원이고 희소한 데이터에 대해서는 성능이 별로 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "small-error",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "elder-publisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6179875333926982\n"
     ]
    }
   ],
   "source": [
    "predicted5 = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted5)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-minnesota",
   "metadata": {},
   "source": [
    "#### -6.6 랜덤 포레스트(Random Forest)\n",
    "#### 결정 트리는 과적합 될 수 있으나 랜덤포레스트는 결정트리보다 오버피팅 가능성이 적음\n",
    "#### 여러개의 나무들이 오렌지인지 사과인지 예측하여 각자의 결과를 투표로 모아서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sustained-transaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 포레스트 훈련\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "recognized-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.701246660730187\n"
     ]
    }
   ],
   "source": [
    "predicted6 = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted6)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-president",
   "metadata": {},
   "source": [
    "#### -6.7 그래디언트 부스팅 트리\n",
    "#### 여러개의 결정 트리를 묶어 만드는 앙상블 모델. 랜덤 포레스트와 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦\n",
    "#### 일반적으로 1-5정도의 깊지 않은 트리만 사용하기 때문에 메모리도 적게 사용하고 예측도 빠름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "median-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       13200.9090           11.46m\n",
      "         2 19141531432.3860           11.41m\n",
      "         3 1018136056482137345428864037762575643679300980036667356656533462569269067776.0000           11.33m\n",
      "         4 5793438208146438552371750463374243580454084126740516228669142075250525372030044080110043136.0000           11.22m\n",
      "         5 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000           10.85m\n",
      "         6 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000           10.54m\n",
      "         7 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000           10.29m\n",
      "         8 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000           10.08m\n",
      "         9 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.89m\n",
      "        10 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.85m\n",
      "        11 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.80m\n",
      "        12 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.75m\n",
      "        13 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.68m\n",
      "        14 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.60m\n",
      "        15 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.52m\n",
      "        16 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.44m\n",
      "        17 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.35m\n",
      "        18 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.26m\n",
      "        19 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.16m\n",
      "        20 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            9.07m\n",
      "        21 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            8.97m\n",
      "        22 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            8.87m\n",
      "        23 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            8.77m\n",
      "        24 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            8.66m\n",
      "        25 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            8.56m\n",
      "        26 3979630484381169793867261128601856110593550227404752540847489843154493525639763256294740889013872088305157670725524817116093080321688237768704.0000            8.46m\n",
      "        27 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            8.35m\n",
      "        28 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            8.25m\n",
      "        29 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            8.14m\n",
      "        30 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            8.03m\n",
      "        31 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.92m\n",
      "        32 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.81m\n",
      "        33 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.70m\n",
      "        34 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.59m\n",
      "        35 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.48m\n",
      "        36 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.37m\n",
      "        37 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.26m\n",
      "        38 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            7.13m\n",
      "        39 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.99m\n",
      "        40 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.88m\n",
      "        41 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.77m\n",
      "        42 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.66m\n",
      "        43 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.55m\n",
      "        44 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.43m\n",
      "        45 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.32m\n",
      "        46 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.19m\n",
      "        47 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.06m\n",
      "        48 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.94m\n",
      "        49 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.81m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        50 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.68m\n",
      "        51 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.56m\n",
      "        52 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.43m\n",
      "        53 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.31m\n",
      "        54 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.20m\n",
      "        55 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            5.09m\n",
      "        56 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.98m\n",
      "        57 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.87m\n",
      "        58 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.76m\n",
      "        59 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.65m\n",
      "        60 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.54m\n",
      "        61 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.42m\n",
      "        62 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.30m\n",
      "        63 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.19m\n",
      "        64 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            4.08m\n",
      "        65 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.97m\n",
      "        66 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.85m\n",
      "        67 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.74m\n",
      "        68 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.63m\n",
      "        69 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.52m\n",
      "        70 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.41m\n",
      "        71 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.30m\n",
      "        72 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.18m\n",
      "        73 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            3.07m\n",
      "        74 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.96m\n",
      "        75 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.84m\n",
      "        76 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.73m\n",
      "        77 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.62m\n",
      "        78 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.51m\n",
      "        79 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.39m\n",
      "        80 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.28m\n",
      "        81 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.17m\n",
      "        82 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            2.05m\n",
      "        83 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.94m\n",
      "        84 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.82m\n",
      "        85 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.71m\n",
      "        86 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.59m\n",
      "        87 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.48m\n",
      "        88 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.36m\n",
      "        89 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.25m\n",
      "        90 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.13m\n",
      "        91 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            1.02m\n",
      "        92 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000           54.45s\n",
      "        93 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000           47.59s\n",
      "        94 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000           40.79s\n",
      "        95 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000           34.00s\n",
      "        96 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000           27.21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        97 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000           20.41s\n",
      "        98 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000           13.61s\n",
      "        99 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            6.80s\n",
      "       100 3979630484381173178473821334674682744399927355192476462279466620274336263041595061252392018927962713273915122067783236783098648441282755559424.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0, verbose=3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 약 12분 정도 소요 됨\n",
    "grbt = GradientBoostingClassifier(random_state=0, verbose=3) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "chubby-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.767586821015138\n"
     ]
    }
   ],
   "source": [
    "predicted7 = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted7)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-daughter",
   "metadata": {},
   "source": [
    "#### -6.8 보팅\n",
    "#### 하드보팅 : 투표용지를 하나씩 주는 것  \n",
    "#### 소프트보팅 : 0부터 9중에서 0을 찾는 것이면 0~9 각 레이블마다 예측한 값을 기록하여 그 값을 평균내서 사용하는 것?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-webcam",
   "metadata": {},
   "source": [
    "#### 로지스틱 회귀, CNB, 그래디언트 부스팅 트리 세가지 사용하여 소프트 보팅으로 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "associate-constitution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0,\n",
       "                                                         verbose=3))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0, verbose=3))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "working-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8161175422974176\n"
     ]
    }
   ],
   "source": [
    "predicted8 = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted8)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "latin-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6731967943009796\n",
      "CNB 정확도: 0.7707034728406055\n",
      "로지스틱 회귀 정확도: 0.8058771148708815\n",
      "SVM 정확도: 0.7666963490650045\n",
      "결정 트리 정확도: 0.6179875333926982\n",
      "랜덤 포레스트 정확도: 0.701246660730187\n",
      "그래디언트 부스팅 트리 정확도: 0.767586821015138\n",
      "보팅 정확도: 0.8161175422974176\n"
     ]
    }
   ],
   "source": [
    "print(\"나이브 베이즈 정확도:\", accuracy_score(y_test, predicted1))\n",
    "print(\"CNB 정확도:\", accuracy_score(y_test, predicted2))\n",
    "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted3))\n",
    "print(\"SVM 정확도:\", accuracy_score(y_test, predicted4))\n",
    "print(\"결정 트리 정확도:\", accuracy_score(y_test, predicted5))\n",
    "print(\"랜덤 포레스트 정확도:\", accuracy_score(y_test, predicted6))\n",
    "print(\"그래디언트 부스팅 트리 정확도:\", accuracy_score(y_test, predicted7))\n",
    "print(\"보팅 정확도:\", accuracy_score(y_test, predicted8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-enlargement",
   "metadata": {},
   "source": [
    "## 3. 직접 단어 갯수 설정해서 사용(15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-livestock",
   "metadata": {},
   "source": [
    "### -1. train, test 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "tight-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=15000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "electric-squad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 수 : 8982\n",
      "테스트 샘플 수 : 2246\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성 확인\n",
    "print('훈련 샘플 수 : {}'.format(len(x_train)))\n",
    "print('테스트 샘플 수 : {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-exhibition",
   "metadata": {},
   "source": [
    "### -2. 원본 뉴스 데이터로 복원(정수 데이터 -> 텍스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "configured-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래와 같이 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 딕셔너리를 제공함. 이를 word_index에 저장하겠음\n",
    "\n",
    "word_index = reuters.get_word_index(path='reuters_word_index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "wicked-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +3 해주기\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "checked-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터의 0, 1, 2 번은 <pad>, <sos>, <unk>라는 자연어 처리를 위한 특별한 토큰들을 위해 맵핑되어진 번호.  \n",
    "# 그래서 만들어진 index_to_word에 추가적으로 이 작업을 해주어야 진짜 index_to_word가 완성됨\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 1은 <sos>, 2는 <unk>를 넣어 줌\n",
    "\n",
    "for index, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "green-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word로 첫번째 훈련용 뉴스 기사를 원래 텍스트로 복원\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-inspection",
   "metadata": {},
   "source": [
    "### -3. 전체 훈련용 뉴스 데이터와 테스트 데이터를 텍스트 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "alpha-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "auburn-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-module",
   "metadata": {},
   "source": [
    "### -4. 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "micro-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "# DTM은 사이킷런의 CountVectorizer()을 통해서 생성할 수 있음\n",
    "# DTM을 생성하고, DTM의 크기를 확인\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-salon",
   "metadata": {},
   "source": [
    "### -5. DTM을 사용해 TF-IDF로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "promising-russell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF는 사이킷런의 TfidfTrnsformer()을 통해서 생성 가능  \n",
    "# TF-IDF는 추가적인 전처리를 하지 않는 이상 DTM과 동일한 크기를 가짐\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-manhattan",
   "metadata": {},
   "source": [
    "### -6. 사이킷런에서 제공하는 머신러닝 모델은 공통적으로 fit()함수를 통해 학습 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-queens",
   "metadata": {},
   "source": [
    "#### -6.1 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "female-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나이브 베이즈 분류기는 사이킷런의 MultinomialNB()를 통해 사용 가능\n",
    "\n",
    "# 사이킷런이 제공하는 머신러닝 모델들은 공통적으로 fit()이라는 함수를 제공하고 있는데\n",
    "# 훈련데이터와 해당 훈련 데이터에 대한 레이블을 인자로 사용하면 모델이 이를 학습함\n",
    "\n",
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "virgin-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.6331255565449688\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 함.  \n",
    "# 다시말해 테스트 데이터도 TF-IDF행렬로 변환해주어야 함. 해당 행렬과 predict() 함수를 통해 에측값을 얻어 정확도를 측정함.\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) # 테스트 데이터를 dtm으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) # dtm을 tf-idf로 변환\n",
    "\n",
    "predicted1 = mod.predict(tfidfv_test) # 테스트 데이터에 대한 예측\n",
    "print('정확도: ', accuracy_score(y_test, predicted1)) # 예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-directive",
   "metadata": {},
   "source": [
    "#### -6.2 CNB(Complement Naive Bayes Classifier)\n",
    "#### 나이브 베이즈 분류기를 보완한 것. 데이터의 불균형을 고려하여 가중치를 부여하는 특징이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "polished-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "quick-bruce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7720391807658059\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted2)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-participant",
   "metadata": {},
   "source": [
    "#### -6.3 로지스틱 회귀(Logistic Regression)(이름은 회귀지만 분류를 수행)\n",
    "#### 소프트맥스 함수를 사용한 다중 클래스 분류 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "danish-hardware",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "center-genesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8125556544968834\n"
     ]
    }
   ],
   "source": [
    "predicted3 = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted3)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-singles",
   "metadata": {},
   "source": [
    "#### -6.4 SVM\n",
    "#### 서포트 벡터(디시전 바운더리에서 가장 가까운 데이터?)만 사용해서 계산랸이 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "comparable-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "square-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.769813000890472\n"
     ]
    }
   ],
   "source": [
    "predicted4 = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted4)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-routine",
   "metadata": {},
   "source": [
    "#### -6.5 결정 트리(decision tree)\n",
    "#### 스무고개 처럼 예/아니오 질문을 통해 학습, 트리계열의 모델들은  고차원이고 희소한 데이터에 대해서는 성능이 별로 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "nuclear-cooper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "looking-juice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6193232413178985\n"
     ]
    }
   ],
   "source": [
    "predicted5 = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted5)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-channels",
   "metadata": {},
   "source": [
    "#### -6.6 랜덤 포레스트(Random Forest)\n",
    "#### 결정 트리는 과적합 될 수 있으나 랜덤포레스트는 결정트리보다 오버피팅 가능성이 적음\n",
    "#### 여러개의 나무들이 오렌지인지 사과인지 예측하여 각자의 결과를 투표로 모아서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cellular-rider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 포레스트 훈련\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "prompt-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6714158504007124\n"
     ]
    }
   ],
   "source": [
    "predicted6 = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted6)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-economy",
   "metadata": {},
   "source": [
    "#### -6.7 그래디언트 부스팅 트리\n",
    "#### 여러개의 결정 트리를 묶어 만드는 앙상블 모델. 랜덤 포레스트와 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦\n",
    "#### 일반적으로 1-5정도의 깊지 않은 트리만 사용하기 때문에 메모리도 적게 사용하고 예측도 빠름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "effective-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       12867.7588           12.36m\n",
      "         2   730517195.5810           11.71m\n",
      "         3 52426240961.5098           11.26m\n",
      "         4 572955846448707528749563296618507038765457410545942528.0000           11.00m\n",
      "         5 1761988519418287540202658257396981492463494756859736592051509137556573860600479744.0000           10.80m\n",
      "         6 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.63m\n",
      "         7 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.47m\n",
      "         8 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.33m\n",
      "         9 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.34m\n",
      "        10 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.35m\n",
      "        11 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.34m\n",
      "        12 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.30m\n",
      "        13 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.25m\n",
      "        14 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.19m\n",
      "        15 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.12m\n",
      "        16 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           10.04m\n",
      "        17 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.96m\n",
      "        18 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.87m\n",
      "        19 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.77m\n",
      "        20 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.60m\n",
      "        21 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.44m\n",
      "        22 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.31m\n",
      "        23 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.21m\n",
      "        24 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.11m\n",
      "        25 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            9.01m\n",
      "        26 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.91m\n",
      "        27 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.81m\n",
      "        28 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.70m\n",
      "        29 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.59m\n",
      "        30 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.49m\n",
      "        31 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.38m\n",
      "        32 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.26m\n",
      "        33 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.15m\n",
      "        34 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            8.04m\n",
      "        35 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.93m\n",
      "        36 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.81m\n",
      "        37 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.70m\n",
      "        38 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.58m\n",
      "        39 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.47m\n",
      "        40 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.35m\n",
      "        41 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.24m\n",
      "        42 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.12m\n",
      "        43 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.00m\n",
      "        44 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            6.89m\n",
      "        45 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            6.77m\n",
      "        46 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            6.65m\n",
      "        47 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            6.51m\n",
      "        48 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            6.37m\n",
      "        49 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            6.24m\n",
      "        50 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            6.11m\n",
      "        51 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.99m\n",
      "        52 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.87m\n",
      "        53 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.75m\n",
      "        54 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.63m\n",
      "        55 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.52m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        56 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.40m\n",
      "        57 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.28m\n",
      "        58 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.16m\n",
      "        59 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            5.04m\n",
      "        60 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.92m\n",
      "        61 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.79m\n",
      "        62 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.67m\n",
      "        63 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.55m\n",
      "        64 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.43m\n",
      "        65 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.31m\n",
      "        66 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.19m\n",
      "        67 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            4.07m\n",
      "        68 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.94m\n",
      "        69 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.82m\n",
      "        70 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.70m\n",
      "        71 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.58m\n",
      "        72 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.46m\n",
      "        73 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.33m\n",
      "        74 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.21m\n",
      "        75 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            3.09m\n",
      "        76 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.97m\n",
      "        77 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.85m\n",
      "        78 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.72m\n",
      "        79 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.60m\n",
      "        80 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.48m\n",
      "        81 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.35m\n",
      "        82 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.23m\n",
      "        83 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            2.11m\n",
      "        84 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.98m\n",
      "        85 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.86m\n",
      "        86 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.74m\n",
      "        87 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.61m\n",
      "        88 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.49m\n",
      "        89 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.36m\n",
      "        90 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.24m\n",
      "        91 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            1.11m\n",
      "        92 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           59.33s\n",
      "        93 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           51.93s\n",
      "        94 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           44.52s\n",
      "        95 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           37.11s\n",
      "        96 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           29.70s\n",
      "        97 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           22.28s\n",
      "        98 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000           14.86s\n",
      "        99 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            7.43s\n",
      "       100 1759787442570566016765056566811045247797243136933711134816622164432437917777407526013667765525766091985683072831844161421312.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0, verbose=3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 약 12분 정도 소요 됨\n",
    "grbt = GradientBoostingClassifier(random_state=0, verbose=3) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aquatic-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "predicted7 = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted7)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-effort",
   "metadata": {},
   "source": [
    "#### -6.8 보팅\n",
    "#### 하드보팅 : 투표용지를 하나씩 주는 것  \n",
    "#### 소프트보팅 : 0부터 9중에서 0을 찾는 것이면 0~9 각 레이블마다 예측한 값을 기록하여 그 값을 평균내서 사용하는 것?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-fifth",
   "metadata": {},
   "source": [
    "#### 로지스틱 회귀, CNB, 그래디언트 부스팅 트리 세가지 사용하여 소프트 보팅으로 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "elect-college",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0,\n",
       "                                                         verbose=3))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0, verbose=3))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "occupied-smart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8165627782724845\n"
     ]
    }
   ],
   "source": [
    "predicted8 = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted8)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "forbidden-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6331255565449688\n",
      "CNB 정확도: 0.7720391807658059\n",
      "로지스틱 회귀 정확도: 0.8125556544968834\n",
      "SVM 정확도: 0.769813000890472\n",
      "결정 트리 정확도: 0.6193232413178985\n",
      "랜덤 포레스트 정확도: 0.6714158504007124\n",
      "그래디언트 부스팅 트리 정확도: 0.7707034728406055\n",
      "보팅 정확도: 0.8165627782724845\n"
     ]
    }
   ],
   "source": [
    "print(\"나이브 베이즈 정확도:\", accuracy_score(y_test, predicted1))\n",
    "print(\"CNB 정확도:\", accuracy_score(y_test, predicted2))\n",
    "print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted3))\n",
    "print(\"SVM 정확도:\", accuracy_score(y_test, predicted4))\n",
    "print(\"결정 트리 정확도:\", accuracy_score(y_test, predicted5))\n",
    "print(\"랜덤 포레스트 정확도:\", accuracy_score(y_test, predicted6))\n",
    "print(\"그래디언트 부스팅 트리 정확도:\", accuracy_score(y_test, predicted7))\n",
    "print(\"보팅 정확도:\", accuracy_score(y_test, predicted8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-relay",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 모델과 비교해 보기\n",
    "위 과정을 통해 나온 최적의 모델과 단어 수 조건에서, 본인이 선택한 다른 모델을 적용한 결과와 비교해 봅시다. 감정분석 등에 사용했던 RNN이나 1-D CNN 등의 딥러닝 모델 중 하나를 선택해서 오늘 사용했던 데이터셋을 학습해 보고 나오는 결과를 비교해 봅시다. 단, 공정한 비교를 위해 이때 Word2Vec 등의 pretrained model은 사용하지 않도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-three",
   "metadata": {},
   "source": [
    "#### 내가 뭘 적용해서 해보기에는 나는 아직도 이걸 어떻게 하는지 모르겠다. 노드를 보고 몇 개 수정하거나 복사하여 붙여넣는 것은 할 수 있지만 이렇게 개인이 새롭게 해봐야 하는 내용이 나오면 어떻게 하는지 이해도 잘 안되고 잘 모르겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-preparation",
   "metadata": {},
   "source": [
    "# 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-elizabeth",
   "metadata": {},
   "source": [
    "## 루브릭 평가내용\n",
    "1. 분류 모델의 accuracy가 기준 이상 높게 나왔는가?  \n",
    "3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.\n",
    "- 노드에서 제공해준 것에 대해선 다 실행해봤고 보팅이 제일 좋은 결과를 얻었다.\n",
    "\n",
    "\n",
    "2. 분류 모델의 F1 score가 기준 이상 높게 나왔는가?  \n",
    "Vocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.\n",
    "- 결과가 좋은 것부터 나쁜 것까지 확인할 수 있었지만 근거해 원인을 분석하기엔 아직 잘 모르겠다.\n",
    "\n",
    "\n",
    "3. 생성모델의 metric(BLEU 등) 기준 이상 높은 성능이 확인되었는가?  \n",
    "동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다.\n",
    "- 어떤 이상이 높은 성능인지 모르겠지만 80%이상이 나왔으니? 만족할만한 것 같다. 원인을 분석하기엔 실력이 부족하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
