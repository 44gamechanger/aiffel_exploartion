{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abandoned-biodiversity",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-symphony",
   "metadata": {},
   "source": [
    "# 11-13. 프로젝트: 뉴스기사 요약해보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "consecutive-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aiffel-\n",
      "[nltk_data]     dj47/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltk패키지에서 불용어 사전을 다운로드 받고 데이터 전처리를 위한 패키지 불러오기\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-trainer",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adapted-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "plain-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출적 요약\n",
    "data2 = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metropolitan-interim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81315</th>\n",
       "      <td>After 24 yrs, Sridevi, Dutt to star together i...</td>\n",
       "      <td>According to reports, actors Sanjay Dutt and S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46947</th>\n",
       "      <td>Punjab woman castrates husband over suspicion ...</td>\n",
       "      <td>A woman in Punjab allegedly cut off her husban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>433 firms under EPFO scanner over PF managemen...</td>\n",
       "      <td>The Employees Provident Fund Organisation (EPF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27871</th>\n",
       "      <td>Air pollution significant contributor behind d...</td>\n",
       "      <td>A study conducted by the researchers at USA's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21909</th>\n",
       "      <td>Spider-shaped robot that can help in medical s...</td>\n",
       "      <td>Researchers from Harvard and Boston have devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>Nissan Chairman used firmÃ¢ÂÂs assets for pe...</td>\n",
       "      <td>Japanese carmaker Nissan's Chairman Carlos Gho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21273</th>\n",
       "      <td>Injury-hit Virat Kohli can be more dangerous: ...</td>\n",
       "      <td>England coach Trevor Bayliss has said that Vir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15847</th>\n",
       "      <td>Apple stole our chip-making secrets, gave it t...</td>\n",
       "      <td>American chipmaker Qualcomm on Tuesday accused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32692</th>\n",
       "      <td>You're Avengers fan if you wait for post-credi...</td>\n",
       "      <td>Information and Broadcasting Minister Smriti I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25893</th>\n",
       "      <td>PM Modi spreading poison of hatred and divisio...</td>\n",
       "      <td>After PM Narendra Modi claimed that he was not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "81315  After 24 yrs, Sridevi, Dutt to star together i...   \n",
       "46947  Punjab woman castrates husband over suspicion ...   \n",
       "35892  433 firms under EPFO scanner over PF managemen...   \n",
       "27871  Air pollution significant contributor behind d...   \n",
       "21909  Spider-shaped robot that can help in medical s...   \n",
       "9472   Nissan Chairman used firmÃ¢ÂÂs assets for pe...   \n",
       "21273  Injury-hit Virat Kohli can be more dangerous: ...   \n",
       "15847  Apple stole our chip-making secrets, gave it t...   \n",
       "32692  You're Avengers fan if you wait for post-credi...   \n",
       "25893  PM Modi spreading poison of hatred and divisio...   \n",
       "\n",
       "                                                    text  \n",
       "81315  According to reports, actors Sanjay Dutt and S...  \n",
       "46947  A woman in Punjab allegedly cut off her husban...  \n",
       "35892  The Employees Provident Fund Organisation (EPF...  \n",
       "27871  A study conducted by the researchers at USA's ...  \n",
       "21909  Researchers from Harvard and Boston have devel...  \n",
       "9472   Japanese carmaker Nissan's Chairman Carlos Gho...  \n",
       "21273  England coach Trevor Bayliss has said that Vir...  \n",
       "15847  American chipmaker Qualcomm on Tuesday accused...  \n",
       "32692  Information and Broadcasting Minister Smriti I...  \n",
       "25893  After PM Narendra Modi claimed that he was not...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-perfume",
   "metadata": {},
   "source": [
    "이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있습니다.\n",
    "\n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있어요. 추출적 요약을 하는 경우에는 오직 text열만을 사용하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-width",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secondary-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "# 중복 여부 확인\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cooperative-pursuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체샘플 수 98360\n"
     ]
    }
   ],
   "source": [
    "# headlines의 경우 간단한 요약으로 같을 수 있지만 text자체가 중복된 건 제거해줘야함\n",
    "data.drop_duplicates(subset='text', inplace=True)\n",
    "print('전체샘플 수', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absolute-parallel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop_duplicates()가 중복된 null을 지워주긴 했지만 여전히 남아 있을 수 있음\n",
    "# .isnull().sum()으로 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunrise-thinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "related-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 제거\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blessed-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "existing-defense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 전처리 전, 후 결과를 확인하기 위해 임의의 text와 summary를 만들어 함수 호출\n",
    "\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_headlines = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_headlines, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "black-temperature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       " 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years',\n",
       " 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터 전체에 대해서 전처리\n",
    "# 이때 text의 경우 불용어를 제거하고 Summary는 불용어를 제거하지 않을 것이므루 따로 호출해서 진행해야함\n",
    "# text를 전처리하고 결과 출력\n",
    "\n",
    "clean_text = []\n",
    "\n",
    "# 전체 Text데이터에 대한 전처리: 10분이상 걸릴 수 있음\n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    \n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cubic-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary에 대해서 불용어 제거를 수행하지 안흔 의미에서 두번째 인자를 False로 넣어줌\n",
    "\n",
    "clean_headlines = []\n",
    "\n",
    "# 전체 summary데이터에 대한 전처리\n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "removable-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정제 과정을 거친 후 empty 샘플이 생겼는지 확인해보느 넋이 좋음\n",
    "# 데이터 정제 저넹는 데이터가 존재했지만, 정제과정에서 문장의 모든 단어가 사라지는 경우가 있음\n",
    "\n",
    "# 보다 쉽게 확인하기 위해 데이터프레임에 재저장 그리고 empty값은 null값을 가진 샘플로 대체\n",
    "\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elementary-secret",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .isnull().sum()을 사용하여 Null값이 생겼는지 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-suffering",
   "metadata": {},
   "source": [
    "#### 훈련데이터와 테스트 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "streaming-broadway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# text와 summary의 최소, 최대, 평균 길이를 구하고 길이 분포를 시각화\n",
    "\n",
    "# 길이 분포 출력 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hispanic-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 최소1, 최대 60, 평균 35\n",
    "# headlines 최소 1 최대 16 평균 9\n",
    "\n",
    "# Text의 최대 길이와 summary의 적절한 최대길이를 임의로 정해봄\n",
    "text_max_len = 45\n",
    "headlines_max_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "whole-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50과 8로 정했을 때 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인\n",
    "# 훈련 데이터와 샘플의 길이를 입력하면 데이터의 몇%가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "given-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 45 이하인 샘플의 비율: 0.9967771451809678\n",
      "전체 샘플 중 길이가 12 이하인 샘플의 비율: 0.9880337535583571\n"
     ]
    }
   ],
   "source": [
    "# 위에서 만든 함수를 text와 summary에 적용해 우리가 결정한 임의이 길이가 몇%의 샘플까지 포함하는지 볼 수 있음\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len, data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "maritime-cylinder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 96871\n"
     ]
    }
   ],
   "source": [
    "# text경우 약 23%의 데이터가 망가진다고 함\n",
    "# 우리는 정해진 길이에 맞춰서 자르는 것이 아닌, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제\n",
    "\n",
    "data = data[data[\"text\"].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data[\"headlines\"].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-kitty",
   "metadata": {},
   "source": [
    "# 시작토큰과 종료토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceramic-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "5  pakistani singer rahat fateh ali khan denied r...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "5  sostoken rahat fateh ali khan denies getting n...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "5  rahat fateh ali khan denies getting notice for...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에 시작, 종료 토큰을 추가\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x: 'sostoken '+x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x: x+' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "floating-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더의 입력, 디코더의 입력과 레이블을 각각 numpy타입으로 저장\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "political-citation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5105 94940  4934 ... 20977 48988  1438]\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "# encoder_input의 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어줌\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "scenic-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 정수 시퀀스를 이용해 다시 데이터의 샘플 순서로 섞어주면 잘 섞인 샘플이 됨\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "collectible-macro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19374\n"
     ]
    }
   ],
   "source": [
    "# 8:2의 비율로 훈련 데이터와 테스트 데이터 분리. \n",
    "# 전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정해줌\n",
    "\n",
    "n_of_val = int(len(encoder_input) * 0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fatty-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 77497\n",
      "훈련 레이블의 개수 : 77497\n",
      "테스트 데이터의 개수 : 19374\n",
      "테스트 레이블의 개수 : 19374\n"
     ]
    }
   ],
   "source": [
    "# 위에 정의한 테스트 데이터의 갯수를 이용해 전체 데이터에 양분\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-multiple",
   "metadata": {},
   "source": [
    "# 단어 집합 및 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "imported-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있음\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 단어로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "distributed-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69023\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47018\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22005\n",
      "단어 집합에서 희귀 단어의 비율: 68.11932254465903\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.511768131767462\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합이 생성되는 동시에 각 단어에 고유 정수가 부여 됨\n",
    "# 생성된 단어 집합은 src_tokenizer.word_index에 저장됨\n",
    "# 이렇게 만든 단어 집합에 모든 데이터를 사용하는 것이 아닌 빈도수가 낮은 단어들을 데이터에서 제외하려고 함\n",
    "# 등장 빈도수가 7회 미만인 단어들 데이터에서 얼만큼 차지하는지 확인\n",
    "# src_tokenizer.word_counts.items() 단어와 각 단어의 등장 빈도수가 저장되어 있음\n",
    "\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받음\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "    \n",
    "    # 단어 등장의 빈도수가 threshold 보다 작으면 \n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt +1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "false-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등장빈도가 6이하인 단어들은 단어 집합에서 약 68%이상을 차지함\n",
    "# 하지만 실제 후련데이터에서 등잔 빈도를 차지하는 비중은 약 3.5%\n",
    "# 그래서 등장 빈도가 6이하인 단어들은 정수 인코딩 과정에서 빼고자 함\n",
    "# 위에서 이를 제외한 단어 집합의 크기를 약 21974으로 계산했는데 비슷하게 단어 집합의 크기를 20000으로 제한\n",
    "\n",
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어크기 20000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "chemical-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134, 626, 501, 743, 596, 1952, 2488, 5560, 250, 714, 72, 15, 1842, 6, 1973, 1076, 7101, 15, 165, 57, 743, 321, 52, 2275, 5615, 727, 5026, 14721, 2660, 6370, 672, 3131, 190, 6190, 41, 3408, 15], [25, 776, 100, 7205, 6517, 7396, 200, 75, 3279, 402, 25, 776, 2168, 118, 974, 193, 75, 136, 589, 4705, 3, 13, 76, 945, 715, 4088, 3169, 634, 6247, 200, 5434, 187, 945, 738, 143, 3279], [920, 1159, 1858, 210, 3529, 134, 741, 161, 5, 143, 6191, 2956, 938, 507, 7102, 2356, 2764, 74, 151, 3651, 210, 992, 17303, 74, 621, 556, 992, 6054, 17, 810]]\n"
     ]
    }
   ],
   "source": [
    "# texts_to_sequence() 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩\n",
    "# 현재는 단어 집합의 크기를 20000으로 제한했으니 이제 20000이 넘는 숫자들은 존재하지 않음\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "brave-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headlines에 대해서도 동일한 작업 진행\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "periodic-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29913\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 18465\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11448\n",
      "단어 집합에서 희귀 단어의 비율: 61.72901414100893\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.014395027446972\n"
     ]
    }
   ],
   "source": [
    "threshold = 5\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "potential-quantum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 158, 1291, 186, 1096, 256, 1646, 1591], [1, 7603, 2818, 106, 5, 115, 89, 6426, 5, 1034], [1, 1659, 109, 739, 6, 990, 220, 643, 6107, 7, 129, 4, 13], [1, 5155, 3, 556, 4, 199, 5596, 34], [1, 63, 26, 649, 1874, 1357, 69, 77, 42, 37, 3759, 1474]]\n",
      "target\n",
      "decoder  [[158, 1291, 186, 1096, 256, 1646, 1591, 2], [7603, 2818, 106, 5, 115, 89, 6426, 5, 1034, 2], [1659, 109, 739, 6, 990, 220, 643, 6107, 7, 129, 4, 13, 2], [5155, 3, 556, 4, 199, 5596, 34, 2], [63, 26, 649, 1874, 1357, 69, 77, 42, 37, 3759, 1474, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 등장 빈도가 4회 이하인 단어는 집합에서 약 61%\n",
    "# 하지만 실제 훈련 데이터에서 등장 빈도는 3.9%\n",
    "# 아까와 동일하게 이 단어들은 모두 제거 어림잡아 10000을 단어 크기로 제한\n",
    "\n",
    "tar_vocab = 10000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "handled-white",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 77497\n",
      "훈련 레이블의 개수 : 77497\n",
      "테스트 데이터의 개수 : 19374\n",
      "테스트 레이블의 개수 : 19374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj47/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 낮은 단어만으로 구성되어잇는 요약문은 0이 됐을수도 있음\n",
    "# 길이가 0이 된 인덱스를 받아올 것\n",
    "# 요약문인 decoder_input에는 sostoken, decoder_target에는 eostokendl 들어가있으므로 실제 길이는 1로 나올 것임\n",
    "\n",
    "# 훈련, 테스트 데이터에 대해서 요약문의 길이가 1인 경우 dorp_train과 drop_test에 저장\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-burke",
   "metadata": {},
   "source": [
    "# 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acting-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-aruba",
   "metadata": {},
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "scheduled-concord",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 함수형 API를 이용해서 인코더 설계\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caring-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 임베딩 벡터의 차원 128로 정의하고, hidden state 크기를 256으로 정의\n",
    "#### hidden state는 LSTM에서 얼만큼의 수용력(capacity)을 가질지를 정하는 파라미터\n",
    "#### 이 파라미터는 LSTM 용량크기나 LSTM에서의 뉴론의 갯수로 이해하면 됨\n",
    "#### 인코더의 LSTM은 3개의 층으로 구성해서 모델의 복잡도를 늘림\n",
    "#### hidden state의 크기를 늘리느 ㄴ것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "empty-subsection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "increased-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10000)  2570000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,249,104\n",
      "Trainable params: 8,249,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 출력층 설계\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-growth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "italian-windsor",
   "metadata": {},
   "source": [
    "## Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "based-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "southern-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10000)  5130000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,940,432\n",
      "Trainable params: 10,940,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 설계한 디코더의 출력층을 아래와 같이 수정\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "classical-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "303/303 [==============================] - 99s 326ms/step - loss: 5.6128 - val_loss: 5.1971\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 101s 333ms/step - loss: 5.0446 - val_loss: 4.8210\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 4.7093 - val_loss: 4.5501\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 97s 322ms/step - loss: 4.4374 - val_loss: 4.3499\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 98s 322ms/step - loss: 4.2176 - val_loss: 4.1974\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 98s 322ms/step - loss: 4.0407 - val_loss: 4.0751\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 98s 323ms/step - loss: 3.8931 - val_loss: 3.9843\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 98s 323ms/step - loss: 3.7646 - val_loss: 3.9085\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 97s 321ms/step - loss: 3.6516 - val_loss: 3.8505\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 98s 322ms/step - loss: 3.5504 - val_loss: 3.7900\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 98s 322ms/step - loss: 3.4610 - val_loss: 3.7543\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 98s 322ms/step - loss: 3.3809 - val_loss: 3.7131\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 97s 320ms/step - loss: 3.3077 - val_loss: 3.6859\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 97s 321ms/step - loss: 3.2445 - val_loss: 3.6666\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 97s 319ms/step - loss: 3.1856 - val_loss: 3.6447\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 97s 319ms/step - loss: 3.1279 - val_loss: 3.6257\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 97s 320ms/step - loss: 3.0743 - val_loss: 3.6006\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 97s 320ms/step - loss: 3.0270 - val_loss: 3.5927\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 97s 320ms/step - loss: 2.9833 - val_loss: 3.5764\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 97s 320ms/step - loss: 2.9445 - val_loss: 3.5674\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 97s 320ms/step - loss: 2.9025 - val_loss: 3.5637\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 99s 325ms/step - loss: 2.8655 - val_loss: 3.5588\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 2.8283 - val_loss: 3.5493\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 98s 325ms/step - loss: 2.7933 - val_loss: 3.5389\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 2.7622 - val_loss: 3.5312\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 2.7311 - val_loss: 3.5267\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 2.7043 - val_loss: 3.5301\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 2.6781 - val_loss: 3.5252\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 99s 326ms/step - loss: 2.6495 - val_loss: 3.5224\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 2.6221 - val_loss: 3.5245\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 2.5996 - val_loss: 3.5243\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 설계한 모델로 훈련 개시\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "satisfied-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 데이터의 손실과 검증 데이터의 손실 줄어드는 과정 시각화\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "endangered-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인퍼런스 모델 구현\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aggressive-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fixed-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 메커니즘알 사용하는 출력층\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aggressive-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-spoke",
   "metadata": {},
   "source": [
    "## Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-framing",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "subject-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fixed-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : former australian captain ian chappell predicted indian spin duo kuldeep yadav yuzvendra chahal excel australia duo also praised credited india success sachin tendulkar chahal yadav managed pick combined wickets sa odi series spin duo bilateral series \n",
      "실제 요약 : chahal yadav will in aus ex aus captain ian chappell \n",
      "예측 요약 :  shane warne has been an wicket clarke\n",
      "\n",
      "\n",
      "원문 : road transport highways minister nitin gadkari ruled exemptions toll collection national highways saying people want good services pay agreeing collection toll tax stopped gadkari added cannot promise exemption toll collection \n",
      "실제 요약 : pay if you want good services union min on toll exemption \n",
      "예측 요약 :  no proposal to stay in vehicles gadkari to gadkari\n",
      "\n",
      "\n",
      "원문 : following maiden test ton india friday glenn maxwell became second australian shane watson player overall score centuries across three formats west indian chris gayle first cricketer achieve feat smashed balls first match inaugural icc world twenty \n",
      "실제 요약 : maxwell becomes nd aussie to score tons across all formats \n",
      "예측 요약 :  st ever bradman to score in test innings\n",
      "\n",
      "\n",
      "원문 : staffers new zealand library found homeless people hiding books premises come back read books could borrowed without home address following shelf auckland based library dedicated homeless store books staffers also show homeless readers regarding fines \n",
      "실제 요약 : library finds homeless people were hiding books to read them \n",
      "예측 요약 :  lakh cocaine found in nz in marijuana\n",
      "\n",
      "\n",
      "원문 : japan space agency revealed plans send first astronaut moon tokyo hopes first join nasa led mission build space station lunar orbit eventually astronauts could sent moon said announcement comes india china develop indigenous space programmes \n",
      "실제 요약 : japan reveals plans to put its st astronaut on moon by \n",
      "예측 요약 :  japan moon mission to moon astronauts in space\n",
      "\n",
      "\n",
      "원문 : dmk president karunanidhi return home hospital within days health condition improved dmk principal secretary said revealing year old leader overcome critical period said able listen saying karunanidhi admitted hospital last week blood pressure dropped \n",
      "실제 요약 : karunanidhi will return home from hospital in days dmk \n",
      "예측 요약 :  karunanidhi karunanidhi hospital passes away at hospital\n",
      "\n",
      "\n",
      "원문 : despite international ban whale hunting japan killed another antarctic whales last summer scientific research killings pregnant termed biological aiming investigate dynamics antarctic marine ecosystem japan killed whales seasons ending also drawing criticism globally \n",
      "실제 요약 : japan kills more whales in annual research faces \n",
      "예측 요약 :  whale whale fossil found in arctic whale study\n",
      "\n",
      "\n",
      "원문 : actress twinkle khanna commenting box office performance husband akshay kumar film toilet ek prem katha tweeted even box office needed toilet eventually break free called film hit writing hit hit film earned crore opening weekend \n",
      "실제 요약 : box office needed this toilet against twinkle \n",
      "예측 요약 :  twinkle shares pic with akshay kumar ek prem katha\n",
      "\n",
      "\n",
      "원문 : actress model anderson penned letter rumoured boyfriend wikileaks founder julian assange thinking julian makes wonder sexiest quality man surely sexiest qualities man bravery courage wrote anderson also lauded standing weak forgotten \n",
      "실제 요약 : pens letter for rumoured boyfriend julian assange \n",
      "예측 요약 :  gigi hadid slams ex us president over racist remark\n",
      "\n",
      "\n",
      "원문 : padma shri sinha became world first woman amputee climb mount everest mount making world first woman amputee scale antarctica highest peak former national level volleyball player lost left leg thrown moving train getting hit another \n",
      "실제 요약 : india world st woman to scale antarctic peak \n",
      "예측 요약 :  st woman to be st woman to woman in china\n",
      "\n",
      "\n",
      "원문 : manchester city defeated arsenal sunday claiming ninth successive league win go eight points clear top premier league table city netted goals games competitions season record start pl club elsewhere defending champions chelsea defeated manchester united clinch third straight league win \n",
      "실제 요약 : man city extend pl lead to points man utd lose to chelsea \n",
      "예측 요약 :  man city post th straight win arsenal register win\n",
      "\n",
      "\n",
      "원문 : case registered telugu actor rao hyderabad police following woman complaint actor women fit sex men remark booked sections indian penal code deal sexual harassment insulting woman modesty \n",
      "실제 요약 : telugu actor booked for women only fit for sex remark \n",
      "예측 요약 :  kannada actor booked for sexual assault\n",
      "\n",
      "\n",
      "원문 : samsung electronics ceo oh apologised shareholders fires galaxy note smartphones said failure arose trying new technology following explosions samsung kill flagship smartphone cost company billion damages samsung investigation revealed two battery issues caused explosions phone \n",
      "실제 요약 : note was failure that from trying new tech samsung \n",
      "예측 요약 :  samsung apologises for selling iphone phones in apple\n",
      "\n",
      "\n",
      "원문 : windies sunil friday became first ever batsman dismissed hit wicket first ball test career debutant stood stumps playing short ball new zealand neil dismissed golden duck th became eleventh player overall get hit wicket test debut \n",
      "실제 요약 : player out hit wicket on test career st ball for st time \n",
      "예측 요약 :  st ever test test bowling was bowls to test debut\n",
      "\n",
      "\n",
      "원문 : indian shooter heena sidhu set commonwealth games record win gold women pistol shooting event tuesday sidhu second medal cwg winning silver women air pistol another indian shooter annu singh came sixth event result india three golds overall eight medals shooting \n",
      "실제 요약 : sidhu sets cwg record to win gold in women pistol \n",
      "예측 요약 :  sidhu wins silver at asian games for th time\n",
      "\n",
      "\n",
      "원문 : guam football association president richard became fifa first asian official convicted fifa corruption scandal admitted us judge accepted almost crore bribes including lakh asian football confederation former president revealed accepted bribes rival factions fifa trying influence election body president \n",
      "실제 요약 : guam football association president admits taking bribes \n",
      "예측 요약 :  desh captain named fifa world cup corruption corruption\n",
      "\n",
      "\n",
      "원문 : actor arnold schwarzenegger french president emmanuel macron trolled us president donald trump snapchat video wherein macron said make planet great trump pulled us paris climate agreement macron statement seemingly references make america great campaign slogan used trump schwarzenegger also called macron great leader \n",
      "실제 요약 : arnold schwarzenegger french prez troll trump on snapchat \n",
      "예측 요약 :  trump tweets on twitter for calling trump climate deal\n",
      "\n",
      "\n",
      "원문 : successfully test fired tuesday defence base odisha coast india first indigenously designed developed long range sub sonic cruise missile operational range km nuclear capable missile cruise altitudes low metres maiden launch missile partial success \n",
      "실제 요약 : what are the features of nuclear capable missile \n",
      "예측 요약 :  india successfully test fires missile successfully\n",
      "\n",
      "\n",
      "원문 : us planned war north korea believed military south korea forces would win conflict korean peninsula newly declassified documents revealed us also considered cruise missile strike north korean nuclear facility began de reactor could provide material bombs \n",
      "실제 요약 : us planned war with korea in documents \n",
      "예측 요약 :  us korea to hold war on north korea\n",
      "\n",
      "\n",
      "원문 : goldman sachs ceo lloyd blankfein said bitcoin feel like currency moves day blankfein said consider bitcoin store value said urgency bank develop bitcoin strategy adding life must really really talking \n",
      "실제 요약 : bitcoin does not like currency goldman sachs ceo \n",
      "예측 요약 :  bitcoin is the world bank ceo\n",
      "\n",
      "\n",
      "원문 : police us state found grams drugs including cocaine methamphetamine marijuana ecstasy synthetic pot woman vagina received tip packet drugs discovered police officials took woman ct scan charged multiple counts possession intent deliver \n",
      "실제 요약 : police find of drugs inside us woman \n",
      "예측 요약 :  us drug cocaine found in drug bag in us\n",
      "\n",
      "\n",
      "원문 : us president donald trump handed favourable news tv screenshots compiled white house communications team twice day report revealed idea twice daily briefing reportedly came former chief staff former press secretary sean spicer competed deliver president \n",
      "실제 요약 : trump gets of positive news twice day report \n",
      "예측 요약 :  trump denies reports of his white house\n",
      "\n",
      "\n",
      "원문 : chinese commerce giant alibaba founder jack become asia richest person net worth billion jack currently ranked world th richest man last week alibaba reported total revenue growth quarter ended june driven growth online sales \n",
      "실제 요약 : alibaba founder jack ma becomes asia richest person \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  jack ma founder becomes world richest man\n",
      "\n",
      "\n",
      "원문 : us secretary state rex tillerson said country policy strategic patience north korea military action east asian country option table exploring new security diplomatic measures tillerson added said north korea could longer allowed continue developing nuclear technology \n",
      "실제 요약 : military action against north korea an option us \n",
      "예측 요약 :  us will not allow pressure to north korea\n",
      "\n",
      "\n",
      "원문 : staff bengaluru st john hospital found two five month old female disposed near hospital premises two separate incidents one foetus found dumped public toilet near hospital emergency ward foetus discovered sanitation tank police cctv footage obtained hospital \n",
      "실제 요약 : female found in bengaluru hospital toilet tank \n",
      "예측 요약 :  bengaluru police staff found dead in toilet toilet\n",
      "\n",
      "\n",
      "원문 : actress anushka sharma featured cover women fashion magazine india october issue seen wearing metallic jacket shade gold tommy paired jacket gold earrings cover story titled keeping real anushka sharma \n",
      "실제 요약 : anushka sharma features on october cover of india \n",
      "예측 요약 :  anushka anushka features on cover of india magazine\n",
      "\n",
      "\n",
      "원문 : delhi court acquitted accused murder case police matched fingerprints murder weapon accused court said police trying make court believe accused waiting police arrive crime scene \n",
      "실제 요약 : court acquits accused as cops forget to match \n",
      "예측 요약 :  malegaon stalking accused murder mastermind rejected\n",
      "\n",
      "\n",
      "원문 : army saturday said foiled infiltration bid sector along loc jammu kashmir killed two militants notably pakistani rangers also opened fire six eight indian posts along border sub sector rs friday night saturday \n",
      "실제 요약 : army kills militants foils infiltration bid in \n",
      "예측 요약 :  army foils infiltration bid by militants along loc\n",
      "\n",
      "\n",
      "원문 : french archaeologists uncovered year old cow skull claiming earliest evidence surgical animal team based claims finding similar holes two human skulls france period however whether surgery performed practise done humans save cow life \n",
      "실제 요약 : humans performed brain surgery on cow years ago study \n",
      "예측 요약 :  year old found in nazi era in\n",
      "\n",
      "\n",
      "원문 : us president donald trump pronounced puerto rico thrice spanish accent event white house friday user tweeted listening trump try pronounce puerto rico spanish accent painful hearing trump say puerto rico spanish accent ultimate test tweeted another user \n",
      "실제 요약 : twitter mocks trump over of puerto rico \n",
      "예측 요약 :  trump calls trump putin putin\n",
      "\n",
      "\n",
      "원문 : sridevi played lead role television series malini iyer aired show story around life tamil brahmin girl married punjabi guy actress turns today made acting debut child artist age tamil film \n",
      "실제 요약 : sridevi played the lead role in tv series malini iyer \n",
      "예측 요약 :  sridevi to star in sridevi in film report\n",
      "\n",
      "\n",
      "원문 : india meteorological department reportedly get two suite new radars next year predicting weather accurately small geographical areas boost department data processing capacity times imd plans improve forecasting capacity kilometre grid imd director general kj ramesh said \n",
      "실제 요약 : met dept to get for accurate weather forecast \n",
      "예측 요약 :  india to get new year to new york reports\n",
      "\n",
      "\n",
      "원문 : india slipped one rank placed th position countries world economic forum global competitiveness index report pakistan jumped seven positions ranked last year however india continues top south asia highest ever score said \n",
      "실제 요약 : india down by rank in global pak up by \n",
      "예측 요약 :  india ranked th in india in report\n",
      "\n",
      "\n",
      "원문 : african country botswana considering use india manufactured electronic voting machines voter verifiable paper audit trail general elections according reports commission also invited professional hackers hack indian evm test reliability amid claims rigged \n",
      "실제 요약 : botswana mulls use of indian evms for general election \n",
      "예측 요약 :  south africa to use evms to hacking elections\n",
      "\n",
      "\n",
      "원문 : survey conducted ngo transparency international india revealed indians paid bribe government official least past one year order get work done survey conducted across states revealed nearly respondents felt corruption increased said went \n",
      "실제 요약 : indians paid bribe at least once in past year survey \n",
      "예측 요약 :  indian indians to get crore in india\n",
      "\n",
      "\n",
      "원문 : actors including randeep hooda dia mirza helped clean mumbai juhu beach post ganesh vivek oberoi keith girlfriend rao also part cleanliness drive organised ngo nearly people gathered beach morning ganesh cleanliness drive \n",
      "실제 요약 : randeep dia help clean beach after ganesh \n",
      "예측 요약 :  naseeruddin irani to walk on hunger strike at mumbai hospital\n",
      "\n",
      "\n",
      "원문 : following consumer complaints telecom regulator trai directed aircel refund balance prepaid subscribers security deposit postpaid subscribers regulator also asked telco submit area wise compliance report may notably aircel filed bankruptcy february year citing intense competition sector \n",
      "실제 요약 : trai directs aircel to refund balance to subscribers \n",
      "예측 요약 :  airtel to challenge airtel to prevent trai\n",
      "\n",
      "\n",
      "원문 : indian table tennis player three medals commonwealth games debut last month signed german bundesliga top division club placed th world rankings start playing bundesliga september jakarta asian games sharath kamal first indian german league \n",
      "실제 요약 : indian who won cwg medals signs with german tt club \n",
      "예측 요약 :  india th cwg champ to return to return to win in\n",
      "\n",
      "\n",
      "원문 : mexico president elect manuel lopez wednesday said cancel billion helicopter deal us country cannot afford expense mexico ordered eight mh helicopters country navy vowed cut government spending soon takes office december \n",
      "실제 요약 : will cancel bn helicopter deal with us mexico prez elect \n",
      "예측 요약 :  mexico to pay bn to pay billion aid to aid israel\n",
      "\n",
      "\n",
      "원문 : held referendum sunday whether change name republic north greece signed deal regard june greece argued name territorial claim province name thus vetoed entry nato european union \n",
      "실제 요약 : holds referendum on changing its name \n",
      "예측 요약 :  catalonia declares independence referendum\n",
      "\n",
      "\n",
      "원문 : responding article said startups exit strategy acquired anand mahindra said bad thing entrepreneurs see route monetise work still would like see many uday want build institutions cannot believe india would better early mahindra added \n",
      "실제 요약 : would like to see many more uday anand mahindra \n",
      "예측 요약 :  we are not going to work with fashion kalaari kalaari md\n",
      "\n",
      "\n",
      "원문 : pope francis tuesday called respect ethnic group speech delivered myanmar avoiding reference rohingya minority community nation works restore peace healing wounds must priority said pope myanmar visit comes amid country military crackdown resulting rohingya refugee crisis \n",
      "실제 요약 : pope avoids mention of rohingyas in key myanmar speech \n",
      "예측 요약 :  pope francis pope francis condemns rohingya violence\n",
      "\n",
      "\n",
      "원문 : german automaker porsche launched latest suv model india starting crore launched new different variants including among others go kmph seconds variant reach kmph seconds \n",
      "실제 요약 : porsche launched in india at crore \n",
      "예측 요약 :  german firm to launch india first electric suv\n",
      "\n",
      "\n",
      "원문 : canada based astronomers successfully observed two intense regions radiation kilometres apart around star light years away earth observation equivalent using telescope earth see insect pluto said researchers rapidly spinning neutron star pulsar seen background gas companion star brown dwarf \n",
      "실제 요약 : astronomers study star light years away in high \n",
      "예측 요약 :  star in star system to be star in star formation\n",
      "\n",
      "\n",
      "원문 : cbse class topper meghna srivastava scored marks english scoring full marks every subject get total marks speaking achievement said expect score many marks secret work hard consistent added \n",
      "실제 요약 : which is the only class topper did not score \n",
      "예측 요약 :  marks odi results class boy reveals cbse class exam\n",
      "\n",
      "\n",
      "원문 : new zealand banned watching netflix drama reasons without supervision adult amid complaints series suicide average two youngsters commit suicide every week new zealand created new censorship category address concerns show show teenager sexual assault suicide \n",
      "실제 요약 : nz bans kids from watching reasons why without adults \n",
      "예측 요약 :  new zealand bans use of life in new zealand\n",
      "\n",
      "\n",
      "원문 : scientists revealed obtained high quality data high resolutions necessary observe shadow black hole milky way galaxy centre scientists final phase studying data collected event horizon telescope international collaboration aiming photograph first black hole virtual earth sized telescope array \n",
      "실제 요약 : scientists close to st ever photo of black hole \n",
      "예측 요약 :  scientists find new theory of universe\n",
      "\n",
      "\n",
      "원문 : near miss incident occurred last week indigo aircraft indian air force jet chennai indigo confirmed jets reportedly came within feet following auto generated resolution advisory warning set indigo pilot steer aircraft safer distance meanwhile dgca probing matter \n",
      "실제 요약 : indigo iaf jets come within feet of each other report \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  plane crash at airport to be held in dubai\n",
      "\n",
      "\n",
      "원문 : accusing state government responsible madhya pradesh farmers plight congress leader kamal nath saturday said party accepted challenge throwing bjp power assembly elections congress reach masses bjp government true face nath added \n",
      "실제 요약 : cong accepts challenge of bjp in mp kamal nath \n",
      "예측 요약 :  congress is not being bjp mp on cong mp polls\n",
      "\n",
      "\n",
      "원문 : india successfully test fired indigenously developed quick reaction surface air short range missile test range odisha coast monday missile developed defence research development organisation bharat electronics limited missile system potential engage multiple targets within range approximately km \n",
      "실제 요약 : india successfully test fires quick reaction missile \n",
      "예측 요약 :  india successfully test fires missile test fired\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약 비교\n",
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-encyclopedia",
   "metadata": {},
   "source": [
    "## Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요.\n",
    "\n",
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-dominant",
   "metadata": {},
   "source": [
    "# 총평"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "classical-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "functioning-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = requests.get('https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "brave-gasoline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "owned-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = str(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "medium-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines,text\n",
      "upGrad learner switches to career in ML & Al with 90% salary hike,\"Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\"\n",
      "Delhi techie wins free food from Swiggy for one year on CRED,\"Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\"\n",
      "New Zealand end Rohit Sharma-led India's 12-match winning streak,\"New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\"\n",
      "Aegon life iTerm insurance plan helps customers save tax,\"With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provid\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "concerned-bacon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-6fb7b50ec0b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Summary:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/summa/summarizer.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, ratio, words, language, split, scores, additional_stopwords)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Creates the graph and calculates the similarity coefficient for every pair of nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0m_set_graph_edge_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Remove all nodes with all edges weights equal to zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/summa/summarizer.py\u001b[0m in \u001b[0;36m_set_graph_edge_weights\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Handles the case in which all similarities are zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/summa/graph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, edge, wt, label, attrs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_neighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_neighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_neighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "separate-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 껼과 값 리스트로 출력\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "covered-facility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-33237631f7ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 단어의 수로 요약문 크기 조절\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Summary:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/summa/summarizer.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, ratio, words, language, split, scores, additional_stopwords)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Creates the graph and calculates the similarity coefficient for every pair of nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0m_set_graph_edge_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Remove all nodes with all edges weights equal to zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/summa/summarizer.py\u001b[0m in \u001b[0;36m_set_graph_edge_weights\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Handles the case in which all similarities are zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/summa/graph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, edge, wt, label, attrs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_neighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_neighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_neighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 단어의 수로 요약문 크기 조절\n",
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-season",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "closing-newfoundland",
   "metadata": {},
   "source": [
    "i love you를 번역하라면 난 사랑해 널 각각의 단어를 번역해서 주는 것이 제일 간단함  \n",
    "하지만 한국어는 조금 어색함. 영어는 svo, 한국어는 sov이기 때문에\n",
    "또 how are you는 잘 지내인데 영어는 3단어 한국어는 2단어 이기때문에 단어별로 반복하는 것은 좋은 방법이 아님\n",
    "\n",
    "RNN\n",
    "인코더 -> 디코더 아키텍처 seq2seq\n",
    "인코더의 역할을 각 단어를 순차적으로 다뤄 문맥벡터를 만드는 것\n",
    "디코더는 문맥벡터로부터 기계번역을 시작하는건 (start - end)\n",
    "그러나 이 방법의 경우 단어의 사이즈가 커질 경우 문제가 생김.\n",
    "문맥벡터는 하나의 고정된 사이즈의 벡터. 문장이 길어질 경우 이것을 고정된 사이즈의 벡터에 담으면 모든 정보를 담을 수 없음\n",
    "충분한 정보가 없기 때문에 충분한 번역이 안됨\n",
    "\n",
    "이것을 어떻게 극복할까\n",
    "그래서 나온게 어텐션 매커니즘\n",
    "Rnn에서는 인코더의 마지막만 컨텍스트백터로 했고 거기서 디코더로 넘어감\n",
    "2가지 이점\n",
    "어텐션에서는 인코더에서 나온 각각의 셀의 state를 활용하면 고정된 컨텍스트 백터의 문제점을 해결할 수 있다.(고정된 컨텍스트 벡터가 아닌 다이나믹한)\n",
    "인코더의 단어들 중에서 집중해야 할 단어들만 집중할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-processor",
   "metadata": {},
   "source": [
    "1, 2번은 따라하기만 해서 했지만 3번 루브릭을 해결하지 못했다.. \n",
    "어떻게 해야하는지.. 잘 모르겠다 ㅠㅠ 아~!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ㅇㄴㄻㅎㅈㅂㅁㄱ둇ㅎ ㄷㅇㄹ\n",
    "\n",
    "뉴스 요약은 내가 제일 관심있는 분야의 노드이기도 한데.. 내용을 잘 이해 못하겠다 ㅠㅠ  \n",
    "노드를 차근차근 하나씩 보면서 이해하고 공부해야할텐데... 그렇게 하면 뭔가 보일텐데... 좀 지쳐서 그런지 뭔가 머리에 잘 안들어온다..\n",
    "이제 아이펠을 약 2개월 정도 진행했는데... 아직도 뭘 제대로 이해하는 것 없이 제출만 하는 것 같아서 답답하다.  \n",
    "한 달 전과 비교 했을 때 흥미도가 조금 떨어진 것 같다. 이전에는 노드에 대해 조금이라도 이해하고 풀어보려고 저녁까지 공부했지만, 두 달 동안 내가 느끼기에는 내가 성장하는..? 느낌을 받지 못하고.. 어차피 내가 노드를 이해 못한다고? 생각해서 그런지, 제출시간이 촉박하니 대충 해서 제출만 하자는 생각만 하는 것 같다.  \n",
    "그래도 희망적인건 파이썬은 조금씩 배우는 것 같다. 물론 이 말이 내가 파이썬을 잘한다는 것도 아니고 지금까지 배운걸 다 활용할 수 있다는 뜻도 아니다. 그래도 파이썬은 기초부터? 배워서 그런지 코드는 퍼실님들이 말씀하셨던 '필요할 때 찾아서 쓸 수 있는' 시도는 해볼 수 있는 것 같다. \n",
    "\n",
    "다시 재밌게 하는 것에 목표를 다잡고 마음을 환기 시켜야겠다~! 화이팅!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-daughter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-flooring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
